[{"categories":["projects"],"content":"Introduction Raspberry Pis are revolutionizing the computer industry. Originally developed to provide low-cost computers to schools, they are expanding far beyond their intended use. This inexpensive technology can be used to accomplish previously unexplored tasks. One such technology is a cluster computer that can run parallel jobs. Many systems built for parallel computing tasks are either expensive or unavailable outside of academia. Supercomputers are expensive to purchase as well as to use, power, and maintain. Although average desktop computers have come down in price, the cost can still become quite high if they require a larger amount of computing power. In today's world of information technology (IT ), it is not new to be confronted daily with new technologies such as cloud computing, cluster computing or high-performance computing. All these terms are approaches that are intended to simplify people's work and lives. Cloud providers such as Microsoft or Amazon make these types of technologies available to customers in the form of services for a fee. Users thus have the opportunity to use the computing power of these technologies without having to buy them at a high price. The advantage here is the almost unlimited scaling of resources. Distributed computing, an infrastructure technology and basis for the provision of cluster computers via the Internet, is used to meet increasing resource demands. By interconnecting and adding remote systems, computing power and performance can be dynamically scaled and provided in theoretically unlimited quantities. ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:0:1","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Motivation and objective of the work Unlimited computing power implies the solution approach to be able to solve seemingly unsolvable and complex problems, such as the simulation of black holes or the calculation of the Milky Way. Expensive supercomputers are oversized when it comes to testing new applications for high-performance computers or solving complex problems. In this work, we address the question of whether we can create an independent and comparable but also less expensive system with few resources, which allows us to solve complex problems in the same way. 24 years ago, Donald Becker and Thomas Sterling started the Beowulf project to create a low-cost alternative but also a powerful alternative to supercomputers. Based on this example, the idea has arisen to pursue the same principle on a smaller scale. The goal of this work is to create an affordable, energy efficient and portable mini-supercomputer. Ideally, a cluster computer with little or no carbon footprint, individual elements that are inexpensive to replace, and a portable system that can be easily disassembled and reassembled. A Raspberry Pi is ideal for this purpose because of its low price, low power consumption, and small size. At the same time, it still offers decent performance, especially when you consider the computing power offered per watt. ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:0:2","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Procedure This paper is divided into 5 parts. The first part is dedicated to the terminological clarification of background information on all technologies involved and how they are related to the cluster. Based on this, the second part clarifies the conceptualization, design, and requirements placed on the system. The main part deals with the construction of the Raspberry Pi cluster and thus forms the practical component, in which design decisions are illustrated and the construction is explained. Following this, important factors such as scalability, performance, cost and energy efficiency are discussed and evaluated. Different use cases are addressed and the technical possibilities are considered. Finally, evaluated evaluations are summarized, limitations are pointed out and future extensions are presented. ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:0:3","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Background This chapter covers the basic technologies that form the basis of parallel and distributed systems. These technologies build on each other, as in a layer system, and are dependent on each other. Architectures and techniques based on this, such as virtualization or cluster computing, in turn provide the basic framework for container virtualization and its management systems. ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:0:4","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Parallel and distributed systems Until computers evolved into distributed computing systems, there have been fundamental changes in various computing technologies over the past decades, which we will briefly discuss in order to make the basic framework of parallel and distributed systems more understandable. ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:0:5","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Amdahl's and Gustafson's law At the beginning of this work, the theoretically unlimited increase of computing power was mentioned. Amdahl's law (named in 1967 after Gene Amdahl) deals exactly with this question, namely whether an unlimited increase in speed can be achieved with an increasing number of processors. It describes, how the parallelization of a software affects the acceleration of this. One divides thereby the software into not parallel, thus sequentially executable and parallel executable portions. Sequential parts are process initializations, communication and the memory management. These parts are necessary for the synchronization of the parallel parts. They form dependencies among themselves and are therefore not able to be executed in parallel. Parallel executable parts are the processors, which are used for computation. It is very important to estimate how much performance gain is achieved by adding a certain number of processing units in parallel working system. Sometimes it happens that adding a larger number of computing units does not necessarily improve the performance, because the expected performance tends to decrease or oversaturate if we blindly add more computing resources. Therefore, it is very important to have a rough estimate of the optimized number of resources to use. Suppose a hypothetical system has only one processor with a normalized runtime of $1$. Now we consider how much time the program needs in the parallelizable portion and denote this portion by $P$. The runtime of the sequential part is thus $(1 - P)$. The runtime of the sequential part does not change, but the parallelizable part is optimally distributed to all processors and therefore runs N times as fast. This results in the following runtime formula: 1 $$\\underset{\\text{sequentiell}}{\\overset{(1 - P)}{︸}} + \\underset{\\text{parallel}}{\\overset{\\frac{P}{N}}{︸}}$$ This is where the time gain comes from: $$Zeitgewinn\\ nach\\ Amdahl\\ = \\ \\frac{ursprüngliche\\ Laufzeit}{\\text{neue\\ Laufzeit}}\\ = \\frac{1}{(1 - P) + \\frac{P}{N}}$$ Here N is the number of processors and P the runtime portion of the parallelizable program. Gene Amdahl called the time or also speed gain Speedup. With the help of a massive parallelism the time of the parallelizable portion can be reduced arbitrarily, the sequential portion remains unaffected thereby however. As the number of processors increases, the communication overhead between the processors also increases, so that above a certain number, they tend to be busy communicating rather than processing the problem. This reduces the performance and refers to this as an overhead in the task distribution. A program cannot be completely parallelized, so that all processors are always busy with work at the same time. No matter how many processor units are used and the proportion of applications that cannot be parallelized is, for example, one percent, the speedup can be a maximum of 100. Gene Amdahl thus concluded that it makes no sense to keep increasing the computing units in order to generate unlimited computing power. 2 Amdahl's model remains valid until the total number of computing operations remains the same while the number of computing units continues to increase. However, if in our hypothetical simulation the job size increases while the number of computational units continues to increase, then Gustafson's law must be invoked. John Gustafson established this law in 1988, which states that as long as the problem being addressed is large enough it can be efficiently parallelized. Unlike Amdahl, Gustafson shows that massive parallelization is nevertheless worthwhile. A parallel system cannot become arbitrarily fast, but it can solve arbitrarily large problems in the same amount of time. 3 ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:0:6","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Client-server model Client-server models are the basic techniques for operating distributed systems. They describe the principle of how tasks and services, such as sending e-mail or providing web applications, are distributed within a network. The corresponding service is centralized on a specific computer, called a server, and the other machines (clients) can use this service. 4 {width=“3.3645833333333335in” height=“3.084465223097113in”} Source: Own representation based on (Schill \u0026 Springer, 2007, p. 31) . []{#_Ref505193493 .anchor}Figure 1 : Illustration of the client-server model. Operating systems (OS) such as Red Hat Enterprise Linux or Windows Server use the above concept and thus provide a client-server system. This is done by establishing the connection to the server on the client side and providing access to services and resources on the server side. Within these operating systems servers are simple programs, which are usually started automatically and run passively in the background. In the Linux environment these programs are called \"daemon\", under Windows Server they are called \"service\". In practice, however, different types of these server services are usually encountered. Examples of this are: 5 Mail server: Communication service for electronic mail (e-mail). Web server: Transmitting web pages to clients. File server: A file server makes files available on a network. ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:0:7","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Peer-to-peer Peer-to-peer (P2P) systems are the opposite of client-server systems. In client-server networks, a server is not necessarily a specific computer. Server and client are referred to as roles in this context, since a computer can also act as a server and a client at the same time. In a P2P system, this distribution of roles does not exist; all computers have equal rights. A computer in a network is a peer because it can be a client and a server at the same time. It can both use and provide services. The functionality, the provision of a service, is therefore provided decentrally in a P2P system. 6 {width=“3.1168832020997375in” height=“2.9405872703412075in”} Source: Own representation based on (Schill \u0026 Springer, 2007, p. 31) . []{#_Toc505443036 .anchor}Figure 2: Illustration of the peer-to-peer model. In contrast to the client-server concept, parallel and distributed systems are not based on P2P systems, but they have been part of the development process of grid and distributed computing and are therefore worth mentioning. 7 ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:0:8","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Grid Computing The volume of data records in databases is increasing and will continue to increase in the coming years. Cluster systems (see 2.2) were developed to handle the complex processing involved and have since become established. However, the demand for computing power and storage capacity is becoming ever greater, especially in scientific areas such as medicine and research or in commercial areas such as e-commerce or financial management. Due to global networking of scientific working methods and international cooperation, more and more information technologies and infrastructures are being interconnected to create collaborative working environments. 8 Grid computing is a distributed computing technique that aims to connect loosely coupled computers and clusters and combine the computing power of all distributed resources into a virtual supercomputer. The basis for integrating these location-independent, cross-institutional, and autonomous resources is the use of existing network infrastructures such as the Internet. The major advantage over cluster systems is the aggregation and sharing of resources such as computers or databases across geographical boundaries. 9 Grid computing can be divided into the following classifications: Computing Grid: access to distributed computing resources. Data Grid: Access to distributed data volumes and storage capacity. Service Grid: Access to distributed applications and services. A computing grid is comparable to a power grid. For the consumer, everything that happens behind a socket is hidden, but he can conveniently use the power offered, the electricity. A computing grid is similar in comparison, it connects to the computing network and uses the computing power offered. High costs or lack of financial resources pose solving complex problems as a difficulty for scientific and economic institutions. But due to the possibility like, the bundling of resources of different organizations, it is possible to solve computationally intensive problems cost-efficiently. 10 ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:0:9","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Public Resource Computing As an analogous counterpart to grid computing, public resource computing (PRC ) and volunteer computing have emerged to harness hidden computing power using distributed computing. The idea and background of this type of distributed computing are that the use of supercomputers is very cost-intensive, on the other hand processors of many computers, such as those of personal computers (PC ), servers or smartphones are not fully utilized. Many users work on their PCs with programs that use only part of the total processor power. To make these unused computing resources usable, a corresponding software client is installed on the respective PCs or servers, which establishes the connection to a computing grid, takes over task distribution and makes unused computing power available. 11 The software platform Berkeley Open Infrastructure for Network Computing (BOINC ) enables the use of this unused computing power of thousands of computers. Examples of computationally intensive PRC projects and complex problems include creating an accurate three-dimensional (3D) model of the Milky Way, searching for extraterrestrial radio waves, and calculating gravitational waves. An example of a special research project that exploits the benefits of grid computing, and can only be realized using it, is grid-based computer simulations of gravitational waves generated by the merger of two singularities (black holes) (see Figure3). 12 Other well-known RPC projects using BOINC are: 13 SETI @home (Search for Extra-Terrestrial Intelligence at home): study of radio signal data from the Arecibo Observatory radio telescope in Puerto Rico used as evidence of extraterrestrial technology. MilkyWay@home: research in modeling and determining the evolution of the Milky Way Galaxy. Einstein@home: The project examines data collected by the LIGO and GEO600 gravitational wave detectors for evidence of periodic sources, such as rapidly rotating neutron stars, which are the gravitational equivalent of pulsars (pulsating radio sources). {width=“4.757228783902012in” height=“3.09375in”} Source: (Kroeker, 2011, p. 15) . []{#_Ref505271426 .anchor}Figure 3 : Grid-based simulation of gravitational waves generated by the merger of two black holes. It is worth mentioning the successes and cost savings achieved through the use of public resource or volunteer computing. Certainly it is possible to solve complex problems through high performance and supercomputers but not with such a small part of costs. For example, the University of Westminster, based in London, has been able to show savings of around £500,000 by using a BOINC supercomputer. 14 ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:0:10","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Distributed Computing Distributed computing or distributed systems, as defined by Andrew S. Tanenbaum, is a collection of independent computers that appear to their users as a single unified system. Distributed computing resource processing deals with the coordination of these distributed computers. In contrast to cluster systems, most computers have different hardware and operating systems. In some cases, resources and programming languages vary greatly. The basic requirement for these machines to work together and exchange data is that they are connected via a network. 15 The computing technologies mentioned so far fall under the umbrella term distributed computing. Figure4 shows how these technologies are classified collectively into distributed computing and, among others, into client-server computing and peer-to-peer. {width=“5.535256999125109in” height=“3.0in”} Source: Own representation based on (Bengel, Baun, Kunze, \u0026 Stucky, 2008, p. 4). . []{#_Ref505271519 .anchor}Figure 4 : Schematic representation of computing technologies. Communication networks such as the Internet form the basis for distributed systems and give the opportunity to connect geographically distant computers. The following prerequisites must be observed to prevent problems: 16 Concurrency: Concurrency in the execution of programs must be ensured. As soon as services and applications are executed in a network of computers, this usually happens at different times and independently of other computers. To ensure this concurrency of applications, it must be possible to scale the system, which means that additional computers can be added to the network as the demand for resources increases. Time synchronization: As soon as systems act together, messages must be exchanged so that appropriate coordination is possible. Messages such as \"System A is performing this action\" and \"System B is performing this action\". For proper coordination of these messages, timestamps are needed to enable proper sequencing of these messages within the distributed system. One method of synchronizing system time is to synchronize with external atomic clocks outside of distributed systems or to use a shared time server that uses the Network Time Protocol (NTP ), a standard protocol for synchronizing clocks on the Internet. Partial failure: Any system, no matter how well secured, can fail, even if it has an availability of 99.9%. The probability of a failure is still 0.1%, which is already a very large amount for a high number of systems. Care must therefore be taken to ensure that there is no single point of failure (SPOF ), the failure of which would result in the failure of the entire system. Other prerequisites, especially in terms of security, that must be taken into account are the use of firewalls and virtual private networks (VPNs). As soon as sensitive data and information are transferred from services on the Internet via distributed resources, these can fall victim to network attacks. Without appropriate security mechanisms, information can be stolen or even falsified. With the help of firewalls, only certain resources can be granted access by means of defined security policies. Using a VPN, entire segments of distributed systems can be isolated and compartmentalized by encrypting the entire network data transmission. 17 ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:0:11","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Cloud computing Cloud computing is used as a term to represent this vision of computing as a service. A cloud is defined as a set of Internet-based application and computing services so that local data storage and application software can be largely or completely dispensed with. From a technical perspective, cloud computing describes the approach of making IT infrastructures, such as physical or virtual hardware, available via a computer network without the user or cloud user having to install anything on their own computer. Cloud providers such as Microsoft or Amazon make these types of technologies available to customers in the form of services for a fee. Users thus have the option of using the computing power of these technologies without having to buy them at a high price. By providing and managing the cloud infrastructure through the provider, the overall costs are reduced and optimized to a minimum. The main advantages of using cloud computing are the almost unlimited scaling of resources, such as computing units or storage capacities. If, for example, a user wants to use a very large quantity of cloud services, it is only a question of cost. The higher a service scales, the higher the costs borne by the customer. 18 Grid computing is seen as the forerunner of cloud computing, although the focus is more on scientific projects and the system is decentralized, i.e. shared. In contrast to grid computing, cloud computing is, from a first perspective, a centralized solution. From a technical point of view, however, and depending on how a cloud service is used by the user, cloud resources can be globally distributed and must communicate with each other in a network for this purpose. This in turn is similar to the approach of grid computing, since a corresponding coordination of these distributed resources is necessary. The most important providers of cloud computing services are currently Amazon Web Services (AWS ), Microsoft with its Azure cloud platform, and Rackspace. 19 In practice, the following three abstraction or business models have become established for the provision of cloud services: 20 On-premise: On-premise means on the customer's own premises or locally on site. The customer is responsible for managing its own IT infrastructure, which it usually administers in its own data center and on its own hardware. PaaS - Platform as a Service: The maintenance and management of hardware, operating systems and runtime environments for computer programs is taken over by the cloud provider. The user focuses only on his applications. A typical example of PaaS is scalable SQL databases (structured query language). IaaS - Infrastructure as a Service: The entire infrastructure consisting of network, storage, server hardware and virtualization layer (see 2.4) is provided by the cloud provider. The user assumes responsibility for the upper layers such as the operating system and applications. SaaS - Software as a Service: In this model, the entire hardware and software infrastructure is offered and managed. The user thus has the option of directly using software services, such as web servers or e-mail, without any effort. The figure below shows a breakdown of the business models mentioned. Here, blue denotes the company's own share of the administration effort. Neutral stands for the segments which the cloud provider manages and administers. {width=“5.885959098862642in” height=“3.5104166666666665in”} Source: Own representation based on (Technet, 2018) . []{#_Toc505443039 .anchor}Figure 5: Comparison of the different cloud computing models. As soon as the term cloud is mentioned, it predominantly refers to a specific usage model of cloud computing. The various types of these usage models are defined below: 21 Private cloud: The English term \"private\" translates into German as \"privat\" and, in the context of cloud, stands for \"not for the public\". A company uses a private cloud in a secure environment such as its own internal networ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:0:12","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Cluster A cluster is a computer network and usually refers to a group of at least 2-n servers, also called nodes. All nodes are connected to each other via a local area network (LAN) and form a logical unit of a supercomputer. Gregory Pfister defines a cluster as follows: 22 \"A cluster is a type of parallel system that consists of interconnected whole computers and is used as a single, unified resource. “ 23 Clusters are the approach to achieving high performance, high reliability, or high throughput by using a collection of interconnected computer systems. Depending on the type of setup, either all nodes are active at the same time to increase computing power, or at least 1-n node is passive so that it can stand in for a failed node in case of failure. For data transmission, all servers are connected to each other via at least two network connections to a network switch. Two network connections are typical, since on the one hand the switch is excluded as SPOF, and on the other hand to be able to realize a higher data transfer. 24 With reference to the current Top 500 list of the world's fastest computers, the term supercomputer is absolutely appropriate. It is clear that several cluster systems are among the ten fastest computers in the world. Computer clusters are used for three different tasks: providing high availability, high performance computing and load balancing. 25 ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:0:13","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Shared and distributed storage According to the von Neumann architecture, a computer has a shared memory that contains both computer program instructions and data. Parallel computers are divided into two variants in this respect, systems with shared or distributed memory. Regardless of which variant is used, all processors must always be able to exchange data and instructions with each other. The memory access takes place via a so-called interconnect, a connection network for the transfer of data and commands. The interconnect in clusters is an important component for exchanging and communicating data between management and load distribution processes. 26 In systems with shared memory, all processors share a memory. The memory is divided into fixed memory modules that form a uniform address space that can be accessed by all processors. The von Neumann bottleneck comes into play here, which means that the interconnect, in this case the data and instruction bus, becomes the bottleneck between memory and processor. Due to the sequential or step-by-step processing of program instructions, only as many actions can be performed as the bus is capable of. As soon as the speed of the bus is significantly lower than the speed of the processors, the processors repeatedly have to wait. In practice, the waiting time is circumvented by the use of buffer memories (cache), which is located between the processor and the memory. This ensures that program commands are available to the processor quickly and directly. 27 {width=“4.895389326334208in” height=“2.939129483814523in”} Source: Own representation based on (Bauke \u0026 Mertens, 2006, p. 22) ; Cf. (Christl, Riedel, \u0026 Zelend, 2007, p. 5) . []{#_Ref505271697 .anchor}Figure 7 : Parallel computers with shared memory connected via the data and instruction bus. Figure7 shows the representation of memory (M) and processors (P) connected via the interconnect. Computer systems with distributed memory, on the other hand, have a separate memory for each processor. In this case, a connection network is required. As soon as a shared memory is dispensed with, the number of processors can be increased without any problems. By using a distributed memory, each processor gains the upper hand over its address space, since it is allocated its own local memory. Similar to distributed memory, communication takes place via an interconnect, which in this case is a local network. The advantage of computer systems with distributed memory is the increase in the number of processors, but the disadvantage lies in the disproportion between computing and communication performance, since the transport of data between CPU (Central Processing Unit) and memory is much slower. The bottleneck is not in the bus as with distributed memory, but in the local network. 28 {width=“4.59375in” height=“2.6052919947506563in”} Source: Own representation based on. (Bauke \u0026 Mertens, 2006, p. 23) ; (Christl, Riedel, \u0026 Zelend, 2007, p. 5) . []{#_Toc505443042 .anchor}Figure 8: Parallel computers with distributed memory, connected via a local area network. As soon as processor systems are operated with shared memory, through the use of multi-core processors, the complexity and expense of the electronics to be implemented increases. This consequently entails higher costs. A single system with, for example, 128 multicore processors is very expensive and is therefore out of the question for massively parallel applications. It is far more cost-effective to operate 128 PCs, for example, with the same hardware, each with one processor and distributed memory. ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:1:0","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Message Passing Interface Message Passing Interfaces (MPI ) is a standardized and portable message passing standard for message transmission between cluster nodes with distributed memory (see Figure9). This concept was developed by a group of researchers from academia and industry to enable the development of a variety of parallel computing architectures. The standard defines syntax and semantics that are useful to a wide variety of users. It is not a standardized protocol, but acts as a programming interface for serial code used by the C and Fortran programming languages. MPI is the most widely used model for parallel and concurrent programming today. Currently used MPI implementations are MPI/Pro and Local Area Multiprocessor (LAM ) MPI. Both implementations are now fixed components of Linux distributions. Another message-based model is the Parallel Virtual Machine (PVM ) platform. This allows several computers with a Windows or Linux operating system to be combined to form a parallel system with distributed memory. 29 {width=“5.329817366579178in” height=“4.229166666666667in”} Source: Own representation based on (Bauke \u0026 Mertens, 2006, p. 45) . []{#_Ref505272051 .anchor}Figure 9 : Message transmission between cluster nodes via the interconnect. ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:1:1","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"High-Availibility Cluster There are many different application scenarios for clusters. The most popular uses are high-availability (HA), high-performance computing (HPC) and load balancing (LB). These types of computer networks are subdivided as follows in the diagram below. {width=“5.3125in” height=“2.375in”} Source: Own representation based on. (Networked Computing: Fundamentals and Applications, 2018) . []{#_Toc505443044 .anchor}Figure 10: Subordination of the different cluster types. High availability cluster or failover cluster pursues the goal of avoiding one or more single points of failure. In a cluster, a specific system component is defined as SPOF as soon as it is designed as non-redundant. A failover cluster is a group of servers configured so that if one or more servers fail, another server automatically takes over their service and continues processing. Each server in the cluster has at least one other teammate, which functions as a so-called standby server or partner server. The simplest variant of an HA cluster is usually found in the 2-node solution, which is either symmetrically or asymmetrically structured, depending on the architecture. An asymmetrically structured cluster is an active/passive cluster, i.e. as soon as one of the nodes has a fault, its passive partner node steps in and takes over its services and function. A symmetrical active/active cluster, on the other hand, keeps both server nodes active. In this case, various services are shared between the two nodes for load balancing. In this case, high availability and load balancing are provided at the same time. If one of the nodes fails, the active partner takes over its services and the cluster remains available, not highly available but still in a running mode. 30 For a standby server to be able to step in as an active server at all, it must use a certain technique to determine that its active partner server is no longer functioning. This is usually done by a so-called heartbeat mechanism. This typically runs as a service on both server nodes. The communication between the services runs over a local, dedicated as well as redundant network. They communicate with each other and check each other for signs of life - their heartbeat. As soon as there are more than 2 nodes in a cluster, they also monitor each other using various heartbeat techniques. Using push heartbeat, active servers send signals to their respective standby servers at a fixed interval. If one of the standby servers no longer receives a signal, it assumes that its partner has failed and takes over the active role. Based on a pull heartbeat, the standby server sends a certain number of requests to its active partner. If the limit of these requests is reached without a valid response from its partner, the partner takes over its services and thus assumes the active part. 31 ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:1:2","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"High-Performance Computing Cluster The goal of HPC clusters is to process complex computing tasks or simulation applications, in parallel on all cluster nodes. The combination of all cluster nodes thus results in immensely high computing power. All nodes must consist of homogeneous or similar hardware components in order to simplify the administration effort and maintenance and to be able to handle error sources more easily. Furthermore, all nodes are connected to each other via a local network and usually access a common data storage. As soon as an application falls into one of the following categories, increased requirements are placed on memory, network and processors: computing-intensive applications memory-intensive applications communication-intensive applications Because of this, these types of clusters must provide high resilience, high availability, and high redundancy. The use of high-performance clusters, takes place in particularly computationally intensive applications, which are often used in the scientific field. 32 Figure11 shows a typical architecture of an HPC cluster. All compute nodes, also called working nodes, are connected via a local network by means of a switch. In addition, there is a so-called shared storage. This should not be confused with shared memory, which is only used in processor systems (see 2.2.1). Shared storage is used for the joint and simultaneous access and exchange or intermediate storage of data, such as specially required application data or databases. Master nodes or front-end nodes form the central work platform for users, on which they can log in via a console terminal and interact with the cluster. Computing jobs are initiated and applications installed via this platform. 33 {width=“5.513170384951881in” height=“1.8958333333333333in”} Source: Own representation based on (Bauke \u0026 Mertens, 2006, p. 52) . []{#_Ref505273269 .anchor}Figure 11 : Typical construct of an HPC cluster. The first multiprocessor clusters trimmed to high-performance computing, such as the VAX-11/780, came onto the market in 1977 under the name VAXCluster or VMSCluster. The technology pioneer at that time was Hewlett-Packard (HP ), then under the company name Digital Equipment Corporation (DEC ). VAX stands for Virtual Address eXtension and, in conjunction with the OpenVMS(virtual memory system) operating system specially developed for this purpose, was a powerful tool in terms of security, stability and low downtimes. Another notable example of an HPC cluster that focuses more on low-cost high-performance computing is a Beowulf cluster, which we will discuss in more detail in Section 2.2.4. 34 ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:1:3","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Load-Balanced Cluster Processing large amounts of data can lead to high loads on individual nodes and must be managed. Server nodes have limited CPU, memory or network capacity and cannot handle all loads on their own. Furthermore, certain applications can only use or rely on a certain number of processors. A load-balanced cluster is a computer network optimized for load distribution. By distributing the data volumes over several identical computers, the system is protected against total failures. Likewise, the function of uniform performance availability is maintained as capacity or computational requirements change during operation. Figure 12 shows a cluster-internal load balancer that distributes client requests evenly across all servers. 35 {width=“3.9450306211723536in” height=“2.6493503937007876in”} Source: Own representation based on (Load-Balanced Cluster, 2018) . []{#_Toc505443046 .anchor}Figure 12: A cluster-internal load balancer distributes client requests evenly to all servers. Management for intelligent distribution of data streams is handled by these various distribution algorithms: Round-Robin algorithm: All computational requests and loads are distributed evenly to each server, regardless of the current number of connections or response times. Round-robin is best suited when the servers in the cluster have equal processing capabilities based on hardware. Otherwise, some servers will receive more requests than they can handle, while others will consume only a portion of their resources. Weighted Round-Robin: A weighted round-robin algorithm takes into account the different processing capabilities of each server. Users manually assign a performance weight to each server, and a scheduling sequence is automatically generated depending on the server weight. Requests are then routed to the different servers according to a round-robin scheduling sequence. This algorithm makes sense as soon as one or more servers have different performance strengths and maintain a performance equilibrium according to their weightings. Least-Connection Algorithm: Only requests are sent to the server in a cluster based on which currently serves the fewest connections. Load-Based Algorithm: Similar to Least-Connection, only certain requests are sent to the cluster; in a load-balanced algorithm, only requests are sent to servers that currently have the lowest load. ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:1:4","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Beowulf Cluster A Beowulf Cluster is a computer design that provides parallel processing across multiple computers to create a low-cost, high-performance supercomputer. The name Beowulf, translated into German, means werewolf and, in this context, comes from an Old English heroic poem and has since stood as a meaningful emblem of the power such a cluster can deliver. The first clusters of this type were developed in 1994 by scientists Thomas Sterling, Donald Becker and Phil Merkey to support the Earth and Space Sciences Project (ESS ) at the National Aeronautics and Space Administration (NASA ). 36 A Beowulf Cluster in practice is typically a collection of generic computers, either commodity PCs or larger server systems, that are independently procured, assembled, and connected via an internal network. A Beowulf cluster consists of two types of computers, a main (master) computer and multiple computer nodes. When a complex problem or large data set is given to a Beowulf cluster, the master computer first runs a program that breaks the problem into small pieces and sends one piece at a time to each node to compute. When the nodes finish their tasks, the master continuously sends more pieces to them until the entire problem is solved. 37 When Thomas Sterling and Donald J. Becker started up their cluster in 1994, it consisted of sixteen Linux PCs, each with 100 MHz Intel DX4 processors. The individual computers were connected via Ethernet for the required data exchange. Several benchmark tests were performed, which test the performance of computers by measuring the number of floating point number calculations possible per second. The measurement is given in Floating Point Operations Per Second (FLOPS ). The results of the tests were surprising with 4.5 MegaFLOPS per node and 60 MegaFLOPS in total. This corresponds to a speedup of 13.33 or an efficiency of 83%. These results are impressive for the reason that this performance was comparable to the supercomputers from IBM and Co. at the time. The remarkable thing, however, is that this cluster was operated at only a fraction of the cost of supercomputers. 38 The following figure shows a Beowulf cluster with 64 PC nodes, which was developed by Phil Merkey at Michigan Technological University, also for the ESS project. {width=“5.636363735783027in” height=“4.224455380577428in”} Source: Own representation based on (Beowulf Cluster Computing, 2018) . []{#_Toc505443047 .anchor}Figure 13: A 64-node Beowulf cluster from Michigan Technological University. ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:1:5","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Virtualization Before we delve a little deeper into the chapter Container Management Systems (see 2.4), we will look at the basic technology of virtualization. This foundational technology is necessary for the operation of container technologies like Docker. In computer science, virtualization refers to the creation of a virtual, rather than actual, version of something, such as an operating system, server, storage device, or network resources. Virtualization refers to a technology in which an application or an entire operating system is abstracted from the actual underlying hardware. In connection with container technologies, a well-known type of virtualization, we distinguish here between two techniques of virtualization, hypervisor-based and container-based virtualization. 39 Hypervisor-based virtualization A key application of virtualization technology is server virtualization, which uses a software layer called a hypervisor to emulate hardware such as memory, CPU, and networking. The guest OS, which normally interacts with real hardware, implements this with a software emulation of that hardware, and often the guest OS has no idea it is running on virtualized hardware. The hypervisor decides which guest OS gets how much memory, processor time and other resources from the host machine. In this case, the host machine runs the host OS and the hypervisor. This means each OS appears to have direct access to the processor and memory, but the hypervisor actually controls the host processor and resources by allocating what is needed by each OS. While the performance of this virtual machine does not match the performance of the OS running on real hardware, the concept of hypervisor-based virtualization works quite well because most OSes and applications do not require full use of the underlying hardware. This allows for greater flexibility, control and isolation by eliminating dependency on a specific hardware platform. Originally intended for server virtualization, the concept of virtualization has expanded to applications, which is implemented using isolated containers. 40 Container-based virtualization Container virtualization or container-based virtualization is a method of virtualizing applications but also entire operating systems. Containers in this sense are isolated partitions that are integrated into the kernel of a host machine. In these isolated partitions, multiple instances of applications can run without the need for an OS. This means that the OS is virtualized, while the containers that run inside the system have processes that have their own identity and are thus isolated from another process in another container. Software running in containers communicates directly with the host kernel and must be executable on the operating system and CPU architecture on which the host is running. By not emulating hardware and booting a complete operating system, containers can be started in a few milliseconds and are more efficient than traditional virtual machines. Container images are typically smaller than virtual machine images because container images do not need to contain device drivers or a core to run an operating system. Because of the compactness of these application containers, they find their predominant use in software development. Developers do not have to set up their development machines by hand; instead, they use pre-built container images. These images are memory maps of entire application structures that can be arbitrarily moved back and forth between different host machines, also called shipping. This is one of the reasons why container-based virtualization has become increasingly popular in recent years. 41 Examples of container platforms are Docker from Docker Inc. and rkt from the developers of the CoreOS operating system, with Docker enjoying increasing popularity in recent years. Compared to virtual machines, Docker represents a simplified solution to virtualization. 42 Figure 14 shows the key differen","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:1:6","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Google Kubernetes The name Kubernetes comes from the Greek and means helmsman or pilot. Kubernetes is known in specialist circles by the acronym K8s. K8s is an acronym where the eight letters \"ubernete\" are replaced by \"8\". Kubernetes provides a platform for scaling, automatically deploying and managing container applications on distributed machines. It is an orchestration tool and supports container tools such as Apache Mesos, Packer, and including Docker. 46 A Kubernetes system consists of master and worker nodes, the same system principle as Docker Engine, with manager instances named master. The smallest unit in a Kubernetes cluster is a pod and runs in the worker nodes. This pod consists of at least one or more containers. A worker node can in turn run multiple pods. A pod is a worker process that shares virtual resources such as network and volume among its containers. 47 {width=“4.344828302712161in” height=“3.1758508311461067in”} Source: Own representation based on (Pods and Nodes, 2018) . []{#_Toc505443050 .anchor}Figure 16: Granular representation of node, pod and container. The following services run on the individual worker nodes: 48 Docker: providing the container engine. kubelet: Agent, which takes over the management of the containers. kube-proxy: Service that handles network management and port forwarding to and from containers. The main nodes take care of the management and controlling of all nodes. The following services are divided here: 49 kube-apiserver: User interface to the nodes. etcd: Storage location of the cluster configurations, the so-called key-value store. kube-scheduler: The scheduler determines, depending on the available resources, which worker nodes are assigned which pods. kube-controller-manager: This manager service takes over the controlling functions and monitors if all nodes are working, which pods are assigned to which service and manages port forwarding. ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:1:7","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Raspberry Pi Credit-card-sized single-board computers (SBCs) such as the Raspberry Pi, developed in the UK by the Raspberry Pi Foundation, were originally intended to promote computer science education in schools. Acronyms like \"RPi\" or the abbreviation \"RasPi\" or \"Pi\" for the Raspberry Pi are mostly common here. Like smartphones, single-board computers are equipped with ARM processors (Advanced RISC Machines). Before the development of ARM in 1983, there were mainly CISC and RISC processors on the market. CISC stands for Complex Instruction Set Computer. Processors with this architecture are characterized by extremely complex instruction sets. Processors with RISC (Reduced Instruction Set Computer) architectures, on the other hand, have a restricted instruction set and therefore also operate with low power requirements. The Pi's board is equipped with a system-on-a-chip (SoC, i.e. single-chip system), which has the identifier BCM2837 from Broadcom. The SoC consists of a 1.2 GHz ARM Cortex-A53 Quad Core CPU, a VideoCore IV GPU (Graphics Processing Unit) and 512 MB of RAM. It does not include a built-in hard drive, but uses an SD card for booting and permanent data storage. It has an Ethernet port based on the RJ45 standard for connecting to a network, an HDMI port for connecting to a monitor or TV, USB (Universal Serial Bus) ports for connecting a keyboard and mouse, and a 3.5 mm jack for audio and video output. 50 {width=“4.247311898512686in” height=“2.8467213473315836in”} Source: Own representation based on (Merkert, 2017, p. 12) . []{#_Ref505275506 .anchor}Figure 17 : Illustration of a Raspberry Pi 3 Model B and its components.… An average of 35 Euros is the price one pays for a Raspberry Pi, which makes it economically suitable for use and integration into a cluster system, since the unit costs for individual nodes are low. 51 General Purpose Input Output (GPIO ) is the name for programmable inputs and outputs for general purposes. A Raspberry Pi has a total of 40 GPIO pins, twelve of which are for power supply and 28 of which serve as an interface to other systems in order to communicate with or control them. GPIO pins 3 and 5 (see Figure18) enable devices such as an LCD display to be addressed by means of an Inter-Integrated Circuit (I2C), a serial data bus. {width=“4.541666666666667in” height=“4.2243055555555555in”} Source: Own representation based on (Raspberry Pi 3 GPIO Pin Chart with Pi, 2018) . []{#_Ref505441873 .anchor}Figure 18 : Illustration of the different GPIO pins of the Raspberry Pi. ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:1:8","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Conception and design In this chapter, we will go into the basic concept of creating a cluster using Raspberry Pi single-board computers. Here, these mini-computers form the basis for constructing a cost-effective and energy-efficient cluster system. Inspired by Joshua Kiepert and his 32-node RPiCluster or Nick Smith and his first design of a 5-node Raspberry Pi cluster, the idea of further developing and improving certain components has emerged, such as increasing the cooling performance by means of an optimized airflow supply, adding and logically arranging further connection possibilities and considering a modular expandability of the cluster. 52 Requirements The main focus in the design of this Raspberry Pi cluster is on the following requirement criteria: Cost Efficiency. Energy efficiency. Scalability. Resilience. Further criteria are a visual and easy-to-read status and information display of current system values, ideal cooling and optimization of the airflow for the best possible removal of heat. Furthermore, the entire design concept is fundamentally based on certain design requirements, which we will discuss in more detail in the design decisions (see 3.2). Cost and energy efficiency The factors of cost and energy efficiency are paramount and predominantly influence the conception and design. In order to keep the acquisition costs as low as possible but still be able to offer efficient computing power, Raspberry Pi single-board computers in version 3 are to be installed. The use of unnecessary cable lengths or heavy and expensive materials such as sheet steel or aluminum for the housing should be avoided. In addition, a weight and further cost saving is to be achieved by using plastic instead of steel screws. The system should be reproducible at low cost and consume as little power as possible. Energy consumption of less than 60 kilowatts per hour is planned, which is comparatively equivalent to the average power consumption of a commercially available light source such as an incandescent lamp. Such low power consumption implies the portability factor, which means that it should also be possible to use this cluster on a mobile basis. Scaling and resilience Scaling is to be considered in this system in two respects. On the one hand, the user should be given the option of connecting the entire system with other clusters in order to be able to scale cluster-wise at this level. Here we also speak of horizontal scaling. On the other hand, it should be possible to scale vertically or node by node within a cluster by adding or removing individual nodes. This is done either automatically using cluster software or by physically adding or removing further single-board computers. Due to the modular structure of the cluster, the primary goal is to expand individual entire clusters, i.e. vertical scaling. In parallel to scaling, failover is an important player when it comes to keeping the cluster alive. As soon as the cluster system scales on the software side, all peripheral components must be designed and optimized accordingly so as not to reach their physical limits, such as maximum storage capacity or computing power. This also applies to components such as the network distributor and the power supply unit. With the help of organizational measures and the creation of technical redundancies, this fail-safety is to be guaranteed. This is also referred to as system availability. Status and information display For a direct perception of current system values such as host name, system time, processor and case temperature, a visual information display should be available in the form of a display. These important and system-critical values should be immediately and directly readable without the help of technical means, such as a keyboard or the connection of an external monitor. Furthermore, this display should have a backlight to be readable even in dark rooms or with little to no light. Cooling Passive cooling and optimized case ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:1:9","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Calculation time 115.1536 seconds 11.2800 seconds []{#_Toc505443071 .anchor}Table 3: Comparison times of the prime number calculation up to 20000. {width=“5.905555555555556in” height=“4.366666666666666in”} Source: Own representation. []{#_Ref505193565 .anchor}Figure 31 : Results of the sysbench benchmark run on node rpi2. The difference in the calculation time is clearly visible. There is a difference of 104 seconds. According to the visible comparisons and as already mentioned in the cost comparison, there is no question that a Linux PC based on the CISC architecture has a higher CPU performance than the Raspberry Pi with an ARM architecture. Energy efficiencyand cooling ARM processors, such as those installed on the Raspberry Pi, have a high energy efficiency with a clock frequency of 1.2 GHz and a power consumption of max. 4 watts. The average power consumption is about 2 watts in idle mode. The switch consumes 2.4 watts at 0.2 amps of current and 12 volts. The total wattage output of the USB charger is made up of all components and sits at the end of the power chain. Summarizing with all installed components, you get a total power consumption of 13.75 watts in idle and 34 watts at maximum load (see Table4). **Power consumption** Component Idle maximum Raspberry Pi 3 Model B 2 Watt 4 Watt Edimax ES-5800G V2 Gigabit Switch (8-Port) 2.4 watt 2.4 watt LCD display module 1602 HD44780 with 0.1 watt 0.1 watt TWIcontroller Antec TRICOOL 92mm 4-pin case fan 1.25 watt 1.25 watt Anear 60 Watt USB Charger (6-Port) - - ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:2:0","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"Total power consumption 13,75 Watt 23,75 Watt []{#_Ref505193596 .anchor}Table 4 : Total power consumption of the PiCube in idle mode and maximum CPU load of 100%. In the following test, CPU load is generated using the Sysbench prime calculation program and advantages and disadvantages are shown by using active cooling and passive cooling elements. We read system values such as temperature, clock frequency and voltage using the following commands in each case: 61 vcgencmd measure_temp vcgencmd scaling_cur_freq vcgencmd measure_volts core []{#_Toc505443081 .anchor}Listing 7: Commands for querying temperature, clock frequency and voltage. In the following, we look at three temperature curves in the case. The CPU clock frequency is 1.2 GHz and the CPU voltage is 1.325 volts over a period of 5 minutes: Temp1: In case, without heatsink on SoC, without active cooling. Temp2: In case, with heatsink on SoC, without active cooling. Temp3: In case, with heatsink on SoC, with active cooling. CPU utilization Temp1 (°C) Temp2 (°C) Temp3 (°C) (%) 0 39 39 44 ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:3:0","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"100 77 77 82 []{#_Toc505443073 .anchor}Table 5: Measured values of heat generation without active cooling. Next, we look at three temperature profiles of a Raspberry Pi processor. The CPU clock frequency is 1.2 GHz and the CPU voltage is 1.325 volts over a period of 10 minutes: Temp1: CPU, without heat sink on SoC, without active cooling. Temp2: CPU, with heat sink on SoC, without active cooling. Temp3: CPU, with heat sink on SoC, with active cooling. {width=“5.041036745406824in” height=“0.9165518372703412in”} {width=“5.0618667979002625in” height=“0.8540594925634296in”} {width=“5.093113517060368in” height=“0.9582130358705162in”} CPU utilization Temp1 (°C) Temp2 (°C) Temp3 (°C) (%) 0 44 31,2 27,8 ","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:4:0","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["projects"],"content":"100 83,3 83,3 69,8 []{#_Toc505443074 .anchor}Table 6: Measured values The heat development of the circuit boards of each individual computer is also taken into account. Although this is low, it increases constantly with the number of nodes installed in the case. The heat development is about 35 degrees Celsius with an average load of a single board. With 5 nodes, this is already around 38 degrees, which corresponds to a factor of around 1.08 per node. If all 5 nodes are overclocked by increasing the processor's clock frequency, this factor increases to 1.1. Temperature differences of 10 degrees in the case and the processor prove that the maximum performance of all hardware nodes cannot be exploited without appropriate cooling. Passive heat sinks and an already implemented active cooling with the help of a case fan can help here. There is no question that the optimized airflow inside the case also contributes to the improved cooling performance. Applicationfall SETI@home After evaluating the cluster, we turn to a use case from the scientific domain. A current PRC project of BOINC is SETI@home, a scientific experiment run by the University of California at Berkeley that uses computers connected to the Internet in the search for extraterrestrial intelligence. One participates by running a free client program on a computer that downloads and analyzes radio telescope data. This project relies on the concept of grid computing. Data sets to be processed are divided into smaller data sets and distributed to all participating clients, who compute and communicate the results to the distributor, which reassembles the computations into an overall data set. The current computing power of the entire BOINC grid is 20600 PetaFLOPS, distributed over nearly 0.9 million computers. SETI@home has a share of about 19.1% of this. 62 In the following, container virtualization is exploited and pre-built BOINC client images of Docker are used. These images are prefabricated containers, which are started as scalable pods on the PiCube and scale automatically in order to utilize the entire computing power of the cluster. To do this, you register with the SETI@home project and create an account. Using this account data, you generate a container application called k8s-boinc-demo and start it on the cluster with a scaling limit of 10 pod instances. In Figure32, you can see from the Kubernetes dashboard how the pods are distributed evenly or according to workload across worker nodes rpi2 to rpi5 after launch. 63 {width=“5.905555555555556in” height=“5.123611111111111in”} Source: Own representation. []{#_Ref505437319 .anchor}Figure 32 : Overview of the utilization, status and distribution of the pods on the nodes rpi2 to rpi5. Within the SETI@home account, we define how the individual clients or pods are utilized. The CPU utilization is left at the default value of 100% and after about 5 minutes you can see how the CPU utilization of all cluster nodes increases to 100% and remains constant at this value (see Figure33). The cluster now computes data of the SETI@home project. {width=“5.905555555555556in” height=“4.076388888888889in”} Source: Own representation. []{#_Ref505278101 .anchor}Figure 33 : The CPU utilization of node rpi3 at 100%. Figure33 shows the computers currently logged in to the grid with our account information. Each pod is identified here as a single client. If we now assume that the number of PiCube clusters increases to ten, the number of pods would multiply by the same factor. With 10 pod instances per cluster, this means 100 active SETI@home clients, which could make their computing power available to the BOINC grid. {width=“5.905555555555556in” height=“6.027777777777778in”} Source: (SETI@home - Your Computers, 2018) []{#_Toc505443068 .anchor}Figure 34: Listing of all logged-in clients or pods in our cluster. As this use case shows, it can be inferred that the scientific utility of this cluster is without question. Using dynamic pod scalin","date":"Friday, Aug 6, 2021","objectID":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/:5:0","tags":["pi"],"title":"Design, construction and evaluation of a Raspberry Pi Cluster","uri":"/projects/conception-construction-and-evaluation-of-a-raspberry-pi-cluster/"},{"categories":["til"],"content":"Today I learned How to find and replace with a newline in Visual Studio Code. In the local searchbox (Ctrl + F) you can insert newlines by pressing Ctrl + Enter. If you use the global search (Ctrl + Shift + F) you can insert newlines by pressing Shift + Enter. If you want to search for multilines by the character literal, remember to check the rightmost regex icon. References  Bookmark this page for easy future reference! --- Visual Studio Code Keyboard Shortcuts Download Visual Studio Code (Mac, Linux, Windows) ","date":"Friday, Aug 6, 2021","objectID":"/til/find-and-replace-with-a-newline-in-visual-studio-code/:0:0","tags":["til"],"title":"Find and replace with a newline in Visual Studio Code","uri":"/til/find-and-replace-with-a-newline-in-visual-studio-code/"},{"categories":["til"],"content":"Today I learned Visual Studio Code Keyboard Shortcuts for Windows, macOs and Linux Visual Studio Code lets you perform most tasks directly from the keyboard. This page lists out the default bindings (keyboard shortcuts). ","date":"Monday, Aug 2, 2021","objectID":"/til/visual-studio-code-keyboard-shortcuts/:0:0","tags":["til"],"title":"Visual Studio Code Keyboard Shortcuts","uri":"/til/visual-studio-code-keyboard-shortcuts/"},{"categories":["til"],"content":"Keyboard Shortcuts for Windows ","date":"Monday, Aug 2, 2021","objectID":"/til/visual-studio-code-keyboard-shortcuts/:1:0","tags":["til"],"title":"Visual Studio Code Keyboard Shortcuts","uri":"/til/visual-studio-code-keyboard-shortcuts/"},{"categories":["til"],"content":"Keyboard Shortcuts for macOS ","date":"Monday, Aug 2, 2021","objectID":"/til/visual-studio-code-keyboard-shortcuts/:2:0","tags":["til"],"title":"Visual Studio Code Keyboard Shortcuts","uri":"/til/visual-studio-code-keyboard-shortcuts/"},{"categories":["til"],"content":"Keyboard Shortcuts for Linux Below are links to the three platform-specific versions (US English keyboard): Visual Studio Code Keyboard shortcuts for Windows Visual Studio Code Keyboard shortcuts for macOS Visual Studio Code Keyboard shortcuts for Linux References  Bookmark this page for easy future reference! --- Key Bindings for Visual Studio Code ","date":"Monday, Aug 2, 2021","objectID":"/til/visual-studio-code-keyboard-shortcuts/:3:0","tags":["til"],"title":"Visual Studio Code Keyboard Shortcuts","uri":"/til/visual-studio-code-keyboard-shortcuts/"},{"categories":["til","PowerShell"],"content":"Today I learned How to get a list of PowerShell Aliases. An alias is an alternate name for a cmdlet, function, executable file, including scripts. PowerShell includes a set of built-in aliases. You can add your own aliases to the current session and to your PowerShell profile. # Cmdlet Get-Alias # Display Alias names (Get-Alias).DisplayName # Display Alias name and definition Get-Alias | select Name, Definition Which gives you the following Outputs Name Definition ---- ---------- ? Where-Object % ForEach-Object ac Add-Content cat Get-Content cd Set-Location chdir Set-Location clc Clear-Content clear Clear-Host clhy Clear-History cli Clear-Item clp Clear-ItemProperty cls Clear-Host clv Clear-Variable cnsn Connect-PSSession compare Compare-Object copy Copy-Item cp Copy-Item cpi Copy-Item cpp Copy-ItemProperty cvpa Convert-Path dbp Disable-PSBreakpoint del Remove-Item diff Compare-Object dir Get-ChildItem dnsn Disconnect-PSSession ebp Enable-PSBreakpoint echo Write-Output epal Export-Alias epcsv Export-Csv erase Remove-Item etsn Enter-PSSession exsn Exit-PSSession fc Format-Custom fhx Format-Hex fl Format-List foreach ForEach-Object ft Format-Table fw Format-Wide gal Get-Alias gbp Get-PSBreakpoint gc Get-Content gcb Get-Clipboard gci Get-ChildItem gcm Get-Command gcs Get-PSCallStack gdr Get-PSDrive gerr Get-Error ghy Get-History gi Get-Item gin Get-ComputerInfo gjb Get-Job gl Get-Location gm Get-Member gmo Get-Module gp Get-ItemProperty gps Get-Process gpv Get-ItemPropertyValue group Group-Object gsn Get-PSSession gsv Get-Service gtz Get-TimeZone gu Get-Unique gv Get-Variable h Get-History history Get-History icm Invoke-Command iex Invoke-Expression ihy Invoke-History ii Invoke-Item ipal Import-Alias ipcsv Import-Csv ipmo Import-Module irm Invoke-RestMethod iwr Invoke-WebRequest kill Stop-Process ls Get-ChildItem man help md mkdir measure Measure-Object mi Move-Item mount New-PSDrive move Move-Item mp Move-ItemProperty mv Move-Item nal New-Alias ndr New-PSDrive ni New-Item nmo New-Module nsn New-PSSession nv New-Variable ogv Out-GridView oh Out-Host popd Pop-Location ps Get-Process pushd Push-Location pwd Get-Location r Invoke-History rbp Remove-PSBreakpoint rcjb Receive-Job rcsn Receive-PSSession rd Remove-Item rdr Remove-PSDrive ren Rename-Item ri Remove-Item rjb Remove-Job rm Remove-Item rmdir Remove-Item rmo Remove-Module rni Rename-Item rnp Rename-ItemProperty rp Remove-ItemProperty rsn Remove-PSSession rv Remove-Variable rvpa Resolve-Path sajb Start-Job sal Set-Alias saps Start-Process sasv Start-Service sbp Set-PSBreakpoint scb Set-Clipboard select Select-Object set Set-Variable shcm Show-Command si Set-Item sl Set-Location sleep Start-Sleep sls Select-String sort Sort-Object sp Set-ItemProperty spjb Stop-Job spps Stop-Process spsv Stop-Service start Start-Process stz Set-TimeZone sv Set-Variable tee Tee-Object type Get-Content where Where-Object wjb Wait-Job write Write-Output References  Bookmark this page for easy future reference! --- Get-Alias about_Alias_Provider ","date":"Sunday, Aug 1, 2021","objectID":"/til/get-powershell-aliases/:0:0","tags":["til","powershell","scripts","get-alias","alias"],"title":"How to get a list of PowerShell Aliases","uri":"/til/get-powershell-aliases/"},{"categories":["documentation"],"content":"This article shows the basic Markdown syntax and format.","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files. Note This article is a shameful copy of the great Grav original page. If you want to know about the extented Markdown syntax of LoveIt theme, please read extended Markdown syntax page. Let’s face it: Writing content for the Web is tiresome. WYSIWYG editors help alleviate this task, but they generally result in horrible code, or worse yet, ugly web pages. Markdown is a better way to write HTML, without all the complexities and ugliness that usually accompanies it. Some of the key benefits are: Markdown is simple to learn, with minimal extra characters, so it’s also quicker to write content. Less chance of errors when writing in Markdown. Produces valid XHTML output. Keeps the content and the visual display separate, so you cannot mess up the look of your site. Write in any text editor or Markdown application you like. Markdown is a joy to use! John Gruber, the author of Markdown, puts it like this: The overriding design goal for Markdown’s formatting syntax is to make it as readable as possible. The idea is that a Markdown-formatted document should be publishable as-is, as plain text, without looking like it’s been marked up with tags or formatting instructions. While Markdown’s syntax has been influenced by several existing text-to-HTML filters, the single biggest source of inspiration for Markdown’s syntax is the format of plain text email. – John Gruber Without further delay, let us go over the main elements of Markdown and what the resulting HTML looks like! Tip  Bookmark this page for easy future reference! ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:0:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"1 Headings Headings from h2 through h6 are constructed with a # for each level: ## h2 Heading ### h3 Heading #### h4 Heading ##### h5 Heading ###### h6 Heading The HTML looks like this: \u003ch2\u003eh2 Heading\u003c/h2\u003e \u003ch3\u003eh3 Heading\u003c/h3\u003e \u003ch4\u003eh4 Heading\u003c/h4\u003e \u003ch5\u003eh5 Heading\u003c/h5\u003e \u003ch6\u003eh6 Heading\u003c/h6\u003e Heading IDs To add a custom heading ID, enclose the custom ID in curly braces on the same line as the heading: ### A Great Heading {#custom-id} The HTML looks like this: \u003ch3 id=\"custom-id\"\u003eA Great Heading\u003c/h3\u003e ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:1:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"2 Comments Comments should be HTML compatible. \u003c!-- This is a comment --\u003e Comment below should NOT be seen: ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:2:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"3 Horizontal Rules The HTML \u003chr\u003e element is for creating a “thematic break” between paragraph-level elements. In Markdown, you can create a \u003chr\u003e with any of the following: ___: three consecutive underscores ---: three consecutive dashes ***: three consecutive asterisks The rendered output looks like this: ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:3:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"4 Body Copy Body copy written as normal, plain text will be wrapped with \u003cp\u003e\u003c/p\u003e tags in the rendered HTML. So this body copy: Lorem ipsum dolor sit amet, graecis denique ei vel, at duo primis mandamus. Et legere ocurreret pri, animal tacimates complectitur ad cum. Cu eum inermis inimicus efficiendi. Labore officiis his ex, soluta officiis concludaturque ei qui, vide sensibus vim ad. The HTML looks like this: \u003cp\u003eLorem ipsum dolor sit amet, graecis denique ei vel, at duo primis mandamus. Et legere ocurreret pri, animal tacimates complectitur ad cum. Cu eum inermis inimicus efficiendi. Labore officiis his ex, soluta officiis concludaturque ei qui, vide sensibus vim ad.\u003c/p\u003e A line break can be done with one blank line. ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:4:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"5 Inline HTML If you need a certain HTML tag (with a class) you can simply use HTML: Paragraph in Markdown. \u003cdiv class=\"class\"\u003e This is \u003cb\u003eHTML\u003c/b\u003e \u003c/div\u003e Paragraph in Markdown. ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:5:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"6 Emphasis ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:6:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"Bold For emphasizing a snippet of text with a heavier font-weight. The following snippet of text is rendered as bold text. **rendered as bold text** __rendered as bold text__ The HTML looks like this: \u003cstrong\u003erendered as bold text\u003c/strong\u003e ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:6:1","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"Italics For emphasizing a snippet of text with italics. The following snippet of text is rendered as italicized text. *rendered as italicized text* _rendered as italicized text_ The HTML looks like this: \u003cem\u003erendered as italicized text\u003c/em\u003e ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:6:2","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"Strikethrough In GFMGitHub flavored Markdown you can do strikethroughs. ~~Strike through this text.~~ The rendered output looks like this: Strike through this text. The HTML looks like this: \u003cdel\u003eStrike through this text.\u003c/del\u003e ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:6:3","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"Combination Bold, italics, and strikethrough can be used in combination. ***bold and italics*** ~~**strikethrough and bold**~~ ~~*strikethrough and italics*~~ ~~***bold, italics and strikethrough***~~ The rendered output looks like this: bold and italics strikethrough and bold strikethrough and italics bold, italics and strikethrough The HTML looks like this: \u003cem\u003e\u003cstrong\u003ebold and italics\u003c/strong\u003e\u003c/em\u003e \u003cdel\u003e\u003cstrong\u003estrikethrough and bold\u003c/strong\u003e\u003c/del\u003e \u003cdel\u003e\u003cem\u003estrikethrough and italics\u003c/em\u003e\u003c/del\u003e \u003cdel\u003e\u003cem\u003e\u003cstrong\u003ebold, italics and strikethrough\u003c/strong\u003e\u003c/em\u003e\u003c/del\u003e ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:6:4","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"7 Blockquotes For quoting blocks of content from another source within your document. Add \u003e before any text you want to quote: \u003e **Fusion Drive** combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. The rendered output looks like this: Fusion Drive combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. The HTML looks like this: \u003cblockquote\u003e \u003cp\u003e \u003cstrong\u003eFusion Drive\u003c/strong\u003e combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. \u003c/p\u003e \u003c/blockquote\u003e Blockquotes can also be nested: \u003e Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue. Nunc augue augue, aliquam non hendrerit ac, commodo vel nisi. \u003e\u003e Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctor odio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam. The rendered output looks like this: Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue. Nunc augue augue, aliquam non hendrerit ac, commodo vel nisi. Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctor odio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam. ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:7:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"8 Lists ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:8:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"Unordered A list of items in which the order of the items does not explicitly matter. You may use any of the following symbols to denote bullets for each list item: * valid bullet - valid bullet + valid bullet For example: * Lorem ipsum dolor sit amet * Consectetur adipiscing elit * Integer molestie lorem at massa * Facilisis in pretium nisl aliquet * Nulla volutpat aliquam velit * Phasellus iaculis neque * Purus sodales ultricies * Vestibulum laoreet porttitor sem * Ac tristique libero volutpat at * Faucibus porta lacus fringilla vel * Aenean sit amet erat nunc * Eget porttitor lorem The rendered output looks like this: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Phasellus iaculis neque Purus sodales ultricies Vestibulum laoreet porttitor sem Ac tristique libero volutpat at Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem The HTML looks like this: \u003cul\u003e \u003cli\u003eLorem ipsum dolor sit amet\u003c/li\u003e \u003cli\u003eConsectetur adipiscing elit\u003c/li\u003e \u003cli\u003eInteger molestie lorem at massa\u003c/li\u003e \u003cli\u003eFacilisis in pretium nisl aliquet\u003c/li\u003e \u003cli\u003eNulla volutpat aliquam velit \u003cul\u003e \u003cli\u003ePhasellus iaculis neque\u003c/li\u003e \u003cli\u003ePurus sodales ultricies\u003c/li\u003e \u003cli\u003eVestibulum laoreet porttitor sem\u003c/li\u003e \u003cli\u003eAc tristique libero volutpat at\u003c/li\u003e \u003c/ul\u003e \u003c/li\u003e \u003cli\u003eFaucibus porta lacus fringilla vel\u003c/li\u003e \u003cli\u003eAenean sit amet erat nunc\u003c/li\u003e \u003cli\u003eEget porttitor lorem\u003c/li\u003e \u003c/ul\u003e ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:8:1","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"Ordered A list of items in which the order of items does explicitly matter. 1. Lorem ipsum dolor sit amet 2. Consectetur adipiscing elit 3. Integer molestie lorem at massa 4. Facilisis in pretium nisl aliquet 5. Nulla volutpat aliquam velit 6. Faucibus porta lacus fringilla vel 7. Aenean sit amet erat nunc 8. Eget porttitor lorem The rendered output looks like this: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem The HTML looks like this: \u003col\u003e \u003cli\u003eLorem ipsum dolor sit amet\u003c/li\u003e \u003cli\u003eConsectetur adipiscing elit\u003c/li\u003e \u003cli\u003eInteger molestie lorem at massa\u003c/li\u003e \u003cli\u003eFacilisis in pretium nisl aliquet\u003c/li\u003e \u003cli\u003eNulla volutpat aliquam velit\u003c/li\u003e \u003cli\u003eFaucibus porta lacus fringilla vel\u003c/li\u003e \u003cli\u003eAenean sit amet erat nunc\u003c/li\u003e \u003cli\u003eEget porttitor lorem\u003c/li\u003e \u003c/ol\u003e Tip If you just use 1. for each number, Markdown will automatically number each item. For example: 1. Lorem ipsum dolor sit amet 1. Consectetur adipiscing elit 1. Integer molestie lorem at massa 1. Facilisis in pretium nisl aliquet 1. Nulla volutpat aliquam velit 1. Faucibus porta lacus fringilla vel 1. Aenean sit amet erat nunc 1. Eget porttitor lorem The rendered output looks like this: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:8:2","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"Task Lists Task lists allow you to create a list of items with checkboxes. To create a task list, add dashes (-) and brackets with a space ([ ]) before task list items. To select a checkbox, add an x in between the brackets ([x]). - [x] Write the press release - [ ] Update the website - [ ] Contact the media The rendered output looks like this: Write the press release Update the website Contact the media ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:8:3","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"9 Code ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:9:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"Inline Code Wrap inline snippets of code with `. In this example, `\u003csection\u003e\u003c/section\u003e` should be wrapped as **code**. The rendered output looks like this: In this example, \u003csection\u003e\u003c/section\u003e should be wrapped as code. The HTML looks like this: \u003cp\u003e In this example, \u003ccode\u003e\u0026lt;section\u0026gt;\u0026lt;/section\u0026gt;\u003c/code\u003e should be wrapped with \u003cstrong\u003ecode\u003c/strong\u003e. \u003c/p\u003e ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:9:1","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"Indented Code Or indent several lines of code by at least four spaces, as in: // Some comments line 1 of code line 2 of code line 3 of code The rendered output looks like this: // Some comments line 1 of code line 2 of code line 3 of code The HTML looks like this: \u003cpre\u003e \u003ccode\u003e // Some comments line 1 of code line 2 of code line 3 of code \u003c/code\u003e \u003c/pre\u003e ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:9:2","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"Block Fenced Code Use “fences” ``` to block in multiple lines of code with a language attribute. ```markdown Sample text here... ``` The HTML looks like this: \u003cpre language-html\u003e \u003ccode\u003eSample text here...\u003c/code\u003e \u003c/pre\u003e ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:9:3","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"Syntax Highlighting GFMGitHub Flavored Markdown also supports syntax highlighting. To activate it, simply add the file extension of the language you want to use directly after the first code “fence”, ```js, and syntax highlighting will automatically be applied in the rendered HTML. For example, to apply syntax highlighting to JavaScript code: ```js grunt.initConfig({ assemble: { options: { assets: 'docs/assets', data: 'src/data/*.{json,yml}', helpers: 'src/custom-helpers.js', partials: ['src/partials/**/*.{hbs,md}'] }, pages: { options: { layout: 'default.hbs' }, files: { './': ['src/templates/pages/index.hbs'] } } } }; ``` The rendered output looks like this: grunt.initConfig({ assemble: { options: { assets: 'docs/assets', data: 'src/data/*.{json,yml}', helpers: 'src/custom-helpers.js', partials: ['src/partials/**/*.{hbs,md}'] }, pages: { options: { layout: 'default.hbs' }, files: { './': ['src/templates/pages/index.hbs'] } } } }; Note Syntax highlighting page in Hugo Docs introduces more about syntax highlighting, including highlight shortcode. ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:9:4","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"10 Tables Tables are created by adding pipes as dividers between each cell, and by adding a line of dashes (also separated by bars) beneath the header. Note that the pipes do not need to be vertically aligned. | Option | Description | | ------ | ----------- | | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | The rendered output looks like this: Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. The HTML looks like this: \u003ctable\u003e \u003cthead\u003e \u003ctr\u003e \u003cth\u003eOption\u003c/th\u003e \u003cth\u003eDescription\u003c/th\u003e \u003c/tr\u003e \u003c/thead\u003e \u003ctbody\u003e \u003ctr\u003e \u003ctd\u003edata\u003c/td\u003e \u003ctd\u003epath to data files to supply the data that will be passed into templates.\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eengine\u003c/td\u003e \u003ctd\u003eengine to be used for processing templates. Handlebars is the default.\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eext\u003c/td\u003e \u003ctd\u003eextension to be used for dest files.\u003c/td\u003e \u003c/tr\u003e \u003c/tbody\u003e \u003c/table\u003e Right or center aligned text Adding a colon on the right side of the dashes below any heading will right align text for that column. Adding colons on both sides of the dashes below any heading will center align text for that column. | Option | Description | |:------:| -----------:| | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | The rendered output looks like this: Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:10:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"11 Links ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:11:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"Basic Link \u003chttps://assemble.io\u003e \u003ccontact@revolunet.com\u003e [Assemble](https://assemble.io) The rendered output looks like this (hover over the link, there is no tooltip): https://assemble.io contact@revolunet.com Assemble The HTML looks like this: \u003ca href=\"https://assemble.io\"\u003ehttps://assemble.io\u003c/a\u003e \u003ca href=\"mailto:contact@revolunet.com\"\u003econtact@revolunet.com\u003c/a\u003e \u003ca href=\"https://assemble.io\"\u003eAssemble\u003c/a\u003e ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:11:1","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"Add a Title [Upstage](https://github.com/upstage/ \"Visit Upstage!\") The rendered output looks like this (hover over the link, there should be a tooltip): Upstage The HTML looks like this: \u003ca href=\"https://github.com/upstage/\" title=\"Visit Upstage!\"\u003eUpstage\u003c/a\u003e ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:11:2","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"Named Anchors Named anchors enable you to jump to the specified anchor point on the same page. For example, each of these chapters: ## Table of Contents * [Chapter 1](#chapter-1) * [Chapter 2](#chapter-2) * [Chapter 3](#chapter-3) will jump to these sections: ## Chapter 1 \u003ca id=\"chapter-1\"\u003e\u003c/a\u003e Content for chapter one. ## Chapter 2 \u003ca id=\"chapter-2\"\u003e\u003c/a\u003e Content for chapter one. ## Chapter 3 \u003ca id=\"chapter-3\"\u003e\u003c/a\u003e Content for chapter one. Note The specific placement of the anchor tag seems to be arbitrary. They are placed inline here since it seems to be unobtrusive, and it works. ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:11:3","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"12 Footnotes Footnotes allow you to add notes and references without cluttering the body of the document. When you create a footnote, a superscript number with a link appears where you added the footnote reference. Readers can click the link to jump to the content of the footnote at the bottom of the page. To create a footnote reference, add a caret and an identifier inside brackets ([^1]). Identifiers can be numbers or words, but they can’t contain spaces or tabs. Identifiers only correlate the footnote reference with the footnote itself — in the output, footnotes are numbered sequentially. Add the footnote using another caret and number inside brackets with a colon and text ([^1]: My footnote.). You don’t have to put footnotes at the end of the document. You can put them anywhere except inside other elements like lists, block quotes, and tables. This is a digital footnote[^1]. This is a footnote with \"label\"[^label] [^1]: This is a digital footnote [^label]: This is a footnote with \"label\" This is a digital footnote1. This is a footnote with “label”2 ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:12:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["documentation"],"content":"13 Images Images have a similar syntax to links but include a preceding exclamation point. ![Minion](https://octodex.github.com/images/minion.png) or: ![Alt text](https://octodex.github.com/images/stormtroopocat.jpg \"The Stormtroopocat\") The StormtroopocatAlt text \" The Stormtroopocat Like links, images also have a footnote style syntax: ![Alt text][id] The DojocatAlt text \" The Dojocat With a reference later in the document defining the URL location: [id]: https://octodex.github.com/images/dojocat.jpg \"The Dojocat\" Tip LoveIt theme has special shortcode for image, which provides more features. This is a digital footnote ↩︎ This is a footnote with “label” ↩︎ ","date":"Sunday, Aug 1, 2021","objectID":"/basic-markdown-syntax/:13:0","tags":["Markdown","HTML"],"title":"Basic Markdown Syntax","uri":"/basic-markdown-syntax/"},{"categories":["TIL"],"content":"Let’s keep it easy with these one-liner’s you can use for Windows as well as Linux to install or update Azure CLI. ","date":"Saturday, Mar 6, 2021","objectID":"/how-to-install-azure-cli/:0:0","tags":["til"],"title":"How to install Azure CLI","uri":"/how-to-install-azure-cli/"},{"categories":["TIL"],"content":"One-liner to install or update Azure CLI on Windows 10 # One-liner to install or update Azure CLI on Windows 10 iwr https://aka.ms/installazurecliwindows -OutFile .\\AzureCLI.msi; start msiexec.exe -Wait -ArgumentList '/I AzureCLI.msi /quiet'; rm .\\AzureCLI.msi Following PowerShell Cmdlet aliases were used *iwr = Invoke-WebRequest *start = Start-Process *rm = Invoke-WebRequest For more details on aliases see How to get a list of PowerShell Aliases Tip You can verify your Azure CLI version with az --version ","date":"Saturday, Mar 6, 2021","objectID":"/how-to-install-azure-cli/:0:1","tags":["til"],"title":"How to install Azure CLI","uri":"/how-to-install-azure-cli/"},{"categories":["TIL"],"content":"One-liner to install or update Azure CLI on Linux # One-liner to install or update Azure CLI on Linux curl -L https://aka.ms/InstallAzureCli | bash Tip The script can also be downloaded and run locally. You may have to restart your shell in order for changes to take effect. References  Bookmark this page for easy future reference! --- Installing various versions of PowerShell How to install the Azure CLI Install the Azure CLI on Linux ","date":"Saturday, Mar 6, 2021","objectID":"/how-to-install-azure-cli/:0:2","tags":["til"],"title":"How to install Azure CLI","uri":"/how-to-install-azure-cli/"},{"categories":["WordPress"],"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme. ","date":"Wednesday, Mar 11, 2020","objectID":"/markdown-syntax-guide/:0:0","tags":["wordpress","markdown","syntax"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":["WordPress"],"content":"Headings The following HTML \u003ch1\u003e—\u003ch6\u003e elements represent six levels of section headings. \u003ch1\u003e is the highest section level while \u003ch6\u003e is the lowest. H1 ","date":"Wednesday, Mar 11, 2020","objectID":"/markdown-syntax-guide/:1:0","tags":["wordpress","markdown","syntax"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":["WordPress"],"content":"H2 ","date":"Wednesday, Mar 11, 2020","objectID":"/markdown-syntax-guide/:2:0","tags":["wordpress","markdown","syntax"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":["WordPress"],"content":"H3 H4 H5 H6 ","date":"Wednesday, Mar 11, 2020","objectID":"/markdown-syntax-guide/:2:1","tags":["wordpress","markdown","syntax"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":["WordPress"],"content":"Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat. Itatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat. ","date":"Wednesday, Mar 11, 2020","objectID":"/markdown-syntax-guide/:3:0","tags":["wordpress","markdown","syntax"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":["WordPress"],"content":"Blockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations. Blockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote. Blockquote with attribution Don’t communicate by sharing memory, share memory by communicating. — Rob Pike1 ","date":"Wednesday, Mar 11, 2020","objectID":"/markdown-syntax-guide/:4:0","tags":["wordpress","markdown","syntax"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":["WordPress"],"content":"Tables Tables aren’t part of the core Markdown spec, but Hugo supports them out-of-the-box. Name Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code ","date":"Wednesday, Mar 11, 2020","objectID":"/markdown-syntax-guide/:5:0","tags":["wordpress","markdown","syntax"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":["WordPress"],"content":"Code Blocks Code block with backticks \u003c!doctype html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\"\u003e \u003ctitle\u003eExample HTML5 Document\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eTest\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e Code block indented with four spaces \u003c!doctype html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\"\u003e \u003ctitle\u003eExample HTML5 Document\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eTest\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e Code block with Hugo’s internal highlight shortcode \u003c!doctype html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\"\u003e \u003ctitle\u003eExample HTML5 Document\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eTest\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e ","date":"Wednesday, Mar 11, 2020","objectID":"/markdown-syntax-guide/:6:0","tags":["wordpress","markdown","syntax"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":["WordPress"],"content":"List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese ","date":"Wednesday, Mar 11, 2020","objectID":"/markdown-syntax-guide/:7:0","tags":["wordpress","markdown","syntax"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":["WordPress"],"content":"Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format. H2O Xn + Yn: Zn Press CTRL+ALT+Delete to end the session. Most salamanders are nocturnal, and hunt for insects, worms, and other small creatures. The above quote is excerpted from Rob Pike’s talk during Gopherfest, November 18, 2015. ↩︎ ","date":"Wednesday, Mar 11, 2020","objectID":"/markdown-syntax-guide/:8:0","tags":["wordpress","markdown","syntax"],"title":"Markdown Syntax Guide","uri":"/markdown-syntax-guide/"},{"categories":["scripts"],"content":"You can do everything with PowerShell, as well as locking your workstation with one simple function call. Just call the LockWorkstation() function in user32.dll and that’s it! The fine thing is, it works on a local and a remote session. Function Lock-WorkStation { rundll32.exe user32.dll, LockWorkStation } References Locking a Computer ","date":"Sunday, Aug 4, 2019","objectID":"/function-lock-workstation-locally-and-remotely/:0:0","tags":["default","powershell","posh","remote"],"title":"Function Lock-Workstation locally and remotely","uri":"/function-lock-workstation-locally-and-remotely/"},{"categories":["Azure","IaaS","Scripts"],"content":"If you need a script which outputs you the overall VMCore amount per region, there you go. This is a snippet from a RunBook which iterates also through each subscription before, so you would get all amount of used cores per subscription as well as per region. I took the advantage of using Get-AzVMUsage. ","date":"Thursday, Feb 21, 2019","objectID":"/get-azure-vm-cores-per-region/:0:0","tags":["automation","powershell","azure","iaas","vm","vcpu","azureregion"],"title":"Get Azure VM Cores (vCPUs) per Region","uri":"/get-azure-vm-cores-per-region/"},{"categories":["Azure","IaaS","Scripts"],"content":"Snippet $AzureLocations = Get-AzLocation | Select-Object DisplayName $Result = @() ForEach ($AzureLocation in $AzureLocations) { $CoreAmount = Get-AzVMUsage -Location $AzureLocation.DisplayName | Where-Object { $_.Name.Value -eq \"virtualMachines\" } | Select-Object currentvalue $Object = New-Object -Type PSCustomObject -Property @{ Location = $AzureLocation.Displayname VMCores = $CoreAmount.CurrentValue } $Object $Result += $Object } $Result ","date":"Thursday, Feb 21, 2019","objectID":"/get-azure-vm-cores-per-region/:0:1","tags":["automation","powershell","azure","iaas","vm","vcpu","azureregion"],"title":"Get Azure VM Cores (vCPUs) per Region","uri":"/get-azure-vm-cores-per-region/"},{"categories":["Azure","IaaS","Scripts"],"content":"Output ","date":"Thursday, Feb 21, 2019","objectID":"/get-azure-vm-cores-per-region/:0:2","tags":["automation","powershell","azure","iaas","vm","vcpu","azureregion"],"title":"Get Azure VM Cores (vCPUs) per Region","uri":"/get-azure-vm-cores-per-region/"},{"categories":["Azure","IaaS","Scripts"],"content":"Okay, yeah there are plenty of scripts out which give you local accounts via WMI or ADSI and yes scripts exist also which give you all local groups but there is not one which gives you both (of course there are also some) but what if you’re looking to implement this as a CustomScriptExtension to your Azure VM? Especially if the Custom Script Extension Output is limited to only 4096 characters? Did you know that? This script was developed to minimize the output of local accounts and their group memberships and gives you a meaningful expression of user accounts sitting on your VM. Check this out: Function Get-LocalAccountMemberships { \u003c# .SYNOPSISRetrieves local user accounts and their group memberships. .DESCRIPTIONRetrieves local user accounts and their group memberships. For having the Output prepared for a Custon Script Extension in Azure Export-Clixml is being used which can then be deserialized with Import-Clixml. .PARAMETERComputerName A single Computer or an array of computer names. The default is localhost ($env:COMPUTERNAME). .PARAMETERGroupName A single stirng or array of Groups to be verified. .EXAMPLEPS Get-LocalAccountMemberships -GroupName Users,Administrators .NOTESAuthor: Sebastian Gräf Email: ps@graef.io Date: December 15, 2017 PSVer: 3.0/4.0/5.0 #\u003e param( [parameter(ValueFromPipeline = $true, ValueFromPipelineByPropertyName = $true)] [array]$ComputerName = $Env:COMPUTERNAME, [array]$GroupName ) $results = @() $arr = @() $LocalAccounts = Get-WmiObject -ComputerName $ComputerName -Class Win32_UserAccount -Filter \"LocalAccount='$True'\" foreach ($LocalAccount in $LocalAccounts) { $obj = New-Object PSObject $obj | Add-Member NoteProperty \"LocalAccount\" $LocalAccount.Caption $obj | Add-Member NoteProperty \"Disabled\" $LocalAccount.Disabled foreach ($Group in $GroupName) { $wmi = Get-WmiObject -ComputerName $ComputerName -Query \"SELECT * FROM Win32_GroupUser WHERE GroupComponent=`\"Win32_Group.Domain='$ComputerName',Name='$Group'`\"\" foreach ($item in $wmi) { $data = $item.PartComponent -split \"\\,\" $domain = ($data[0] -split \"=\")[1] $name = ($data[1] -split \"=\")[1] $arr += (\"$domain\\$name\").Replace(\"\"\"\", \"\") } if ($arr -contains $LocalAccount.Caption) { $obj | Add-Member NoteProperty \"$Group\" \"true\" } else { $obj | Add-Member NoteProperty \"$Group\" \"false\" } } $results += $obj } $results } $output = Get-LocalAccountMemberships -GroupName Users, Administrators, 'Remote Desktop Users' | Export-Clixml output.xml gc output.xml A simple output of Get-LocalAccountMemberships looks like this So, while exporting your output with the help of Export-Clixml and showing the output of your XML file again in the console output as a readable xml structure. Once a script was being run on a VM the common output of the Custom Script Extensions looks like this: You can grab this output of your CustomScriptExtension on your VM with the help of that: $output = Get-AzureRmVMDiagnosticsExtension -ResourceGroupName $ResourceGroupName -VMName $vmName -Name \"Get-LocalAccountMemberships\" -Status $output = $output.SubStatuses[0].Message $output -replace '\\\\n','' | Out-File output.xml -Force $output = Import-Clixml output.xml The trick here is to get the output message from your CustomScriptExtension with $output.SubStatuses[0].Message, removing every \\n, save it and import it as a readable xml structure. Once digested and imported with Import-Clixml you get the same output as before. So why are we doing it this way? Consider that, you’re going to execute a Custom Script Extension on your VM without having remote access to it, yes you don’t have access to it BUT you know you can use the Azure VMAgent which is by default installed on every VM in Azure. With having a Custom Script Extension executed including any of your script, e.g. “Get-LocalAccountMemberships” you can grab details from your machine without accessing it at all. ","date":"Thursday, Feb 21, 2019","objectID":"/get-local-account-memberships/:0:0","tags":["windows","powershell","posh","remote"],"title":"Get Local Account Memberships","uri":"/get-local-account-memberships/"},{"categories":["WordPress"],"content":"The main configuration of WordPress is handled by wp-config.php which is responsible for database access, language, API keys, security and more. Anything changed in this file takes direct influence to your site’s settings and appearance. Settings set in wp-config.php are considered as global and overwrite all parameters in your admin panel. General define('WP_HOME', 'https://www.graef.io'); // Main URL define('WP_SITEURL', 'https://www.graef.io'); // Site URL Deactivate Automatic Updates define( 'AUTOMATIC_UPDATER_DISABLED', true ); Disable Filter for Uploads define( 'ALLOW_UNFILTERED_UPLOADS', true ); Automatically Empty Recycle Bin define ('EMPTY_TRASH_DAYS', 7); define ('EMPTY_TRASH_DAYS', 0); Deactivate Editor for Themes and Plugins define( 'DISALLOW_FILE_EDIT', true ); Set Default Theme for WordPress define( 'WP_DEFAULT_THEME', 'default-theme-folder-name' ); ","date":"Thursday, Feb 21, 2019","objectID":"/wordpress-basic-settings-in-configphp/:0:0","tags":["wordpress","wp-config","php"],"title":"Wordpress Basic Settings in config.php","uri":"/wordpress-basic-settings-in-configphp/"},{"categories":["cloud"],"content":"Requirements ","date":"Thursday, Aug 9, 2018","objectID":"/get-aad-tenant-id-and-subscription-id/:1:0","tags":["default","powershell","posh","remote"],"title":"Get Azure Active Directoy Tenant ID and Subscription ID","uri":"/get-aad-tenant-id-and-subscription-id/"},{"categories":["cloud"],"content":"Install the Azure PowerShell Install-Module -Name Az -AllowClobber -Scope CurrentUser ","date":"Thursday, Aug 9, 2018","objectID":"/get-aad-tenant-id-and-subscription-id/:1:1","tags":["default","powershell","posh","remote"],"title":"Get Azure Active Directoy Tenant ID and Subscription ID","uri":"/get-aad-tenant-id-and-subscription-id/"},{"categories":["cloud"],"content":"Get Tenant and Subscription Details during Login To get your Tenant ID / Name and Subscription ID / Name you have several options with PowerShell, one option is using Connect-AzAccount which directly gives you your default Subscription Name as well as your default Tenant ID after logging in. ","date":"Thursday, Aug 9, 2018","objectID":"/get-aad-tenant-id-and-subscription-id/:2:0","tags":["default","powershell","posh","remote"],"title":"Get Azure Active Directoy Tenant ID and Subscription ID","uri":"/get-aad-tenant-id-and-subscription-id/"},{"categories":["cloud"],"content":"Get Tenant and Subscription details from the Context Another option is using Get-AzContext | Select-Object * which gets the metadata used to authenticate Azure Resource Manager requests. Some more details you get with Get-Aztenant which gets tenants that are authorized for your current user. References Install Azure PowerShell Connect-AzAccount Get-AzContext Get-AzTenant ","date":"Thursday, Aug 9, 2018","objectID":"/get-aad-tenant-id-and-subscription-id/:3:0","tags":["default","powershell","posh","remote"],"title":"Get Azure Active Directoy Tenant ID and Subscription ID","uri":"/get-aad-tenant-id-and-subscription-id/"},{"categories":["scripts"],"content":"As published in my Technet Gallery Script Center here, you can get current timezones remotely via PowerShell with Get-Timezones. Get-Timezones is using WMI to communicate with your servers. Function Get-Timezones { \u003c# .SYNOPSISRetrieves timezones of local or remote computers via WMI. .DESCRIPTIONRetrieves timezones of local or remote computers via WMI. .PARAMETERComputerName A single Computer or an array of computer names. The default is localhost ($env:COMPUTERNAME). .PARAMETERCredentials Commit Credentials for a different domain. .PARAMETERVerbose Run in Verbose Mode. .EXAMPLEPS C:\\\u0026amp;amp;amp;gt; Get-Timezones -ComputerName (gc 'C:\\computers.txt') -Credentials Get-Credential ComputerName TimezoneName DaylightSaving TimezoneCaption ------------ ------------ -------------- --------------- SERVER01 W. Europe Standard Time yes (UTC+01:00) Amsterdam, Berlin, Bern, Rome, Stockholm, Vienna SERVER02 W. Europe Standard Time yes (UTC+01:00) Amsterdam, Berlin, Bern, Rome, Stockholm, Vienna .NOTESAuthor: Sebastian Gräf Website: https://graef.io Email: ps@graef.io Date: June 27, 2017 PSVer: 3.0/4.0/5.0 #\u003e [Cmdletbinding()] Param ( [Parameter(ValueFromPipelineByPropertyName = $true, ValueFromPipeline = $true)] $ComputerName = $Env:COMPUTERNAME, [Parameter(ValueFromPipelineByPropertyName = $true, ValueFromPipeline = $true)] [ValidateNotNull()] [System.Management.Automation.PSCredential][System.Management.Automation.Credential()] $Credentials = [System.Management.Automation.PSCredential]::Empty ) Begin { Write-Verbose \" [$($MyInvocation.InvocationName)] :: Start Process\" $Results = @() $ProgressCounter = 0 } Process { foreach ($Computer in $ComputerName) { $ProgressCounter++ Write-Progress -activity \"Running on $Computer\" -status \"Please wait ...\" -PercentComplete (($ProgressCounter / $ComputerName.length) * 100) if (Test-Connection $Computer -Count 1 -Quiet) { Write-Verbose \" [$($MyInvocation.InvocationName)] :: Processing $Computer\" try { $win32_timezone = Get-WmiObject -Class win32_timezone -ComputerName $Computer -ErrorAction Stop -Credential $Credentials if ($win32_timezone.DaylightBias -eq 0) { $daylightsaving = \"no\" } else { $daylightsaving = \"yes\" } $obj = New-Object -Type PSCustomObject -Property @{ ComputerName = $Computer TimezoneCaption = $win32_timezone.Caption TimezoneName = $win32_timezone.StandardName DaylightSaving = $daylightsaving } $Results += $obj } catch { Write-Verbose \" Host [$Computer] Failed with Error: $($Error[0])\" } } else { Write-Verbose \" Host [$Computer] Failed Connectivity Test\" } } $Results | select ComputerName, TimezoneName, DaylightSaving, TimezoneCaption } End { Write-Progress -activity \"Running on $Computer\" -Status \"Completed.\" -Completed Write-Verbose \" [$($MyInvocation.InvocationName)] :: End Process\" } } This will give you following output: With Set-Timezone you can set timezones remotely. If you need to disable automatic daylight saving time you can add the additional parameter DSTOff. Function Set-Timezones { \u003c# .SYNOPSISSets and retries timezones on local or remote computers via WinRM and enables or disables daylight saving. .DESCRIPTIONThis PowerShell function sets and retrieves the timezone of a local or remote computer using WinRM (Invoke-Command). It also enables or disables dayligt saving times. The function accepts pipeline input and outputs to the pipeline as well as credentials if you want to run it for a specific domain. If the remote computer won't be accessible the function will catch the error but will continue to work. You can use tzutil /l to get a list of available time zone IDs. Timezone TimeZoneID --------- ---------- (UTC-06:00) Central Time (US \u0026amp;amp;amp;amp; Canada) Central Standard Time (UTC) Coordinated Universal Time UTC (UTC+01:00) Amsterdam, Berlin, Bern, Rome, Stockholm, Vienna W. Europe Standard Time .PARAMETERTimezoneID A single Computer or an array of computer names. The default is localhost ($env:COMPUTERNAME). .PARAMETERDSTOff Enables or disables Daylight Savi","date":"Thursday, Jun 28, 2018","objectID":"/get-and-set-timezones-via-powershell-remotely/:0:0","tags":["timezone","powershell","posh","remote"],"title":"Get and Set Timezones via PowerShell remotely","uri":"/get-and-set-timezones-via-powershell-remotely/"},{"categories":["IaaS"],"content":"The purpose of this article is to show how to adjust Windows Failover Cluster “Response to resource failure” policy. If a Cluster Core Resource like File Share Witness or Disk Quorum is in a failing state and offline, the cluster runs into jeopardy and will fail once the active node gets rebooted as no vote can be set to the quorum. To avoid this you should decrease the value of time your cluster core resource attempts to restart. The lower the value the higher the amount of retries your resource has to restart itself. To increase restart attempts for the Cluster Core Resource you need to adjust the “Response to resource failure” policy from one hour to 15 minutes. So with a given period for restarts of 15 minutes, maximum restarts in the specified period of 1 and “If all the restart attempts fail, begin restarting again after the specified period of period” of 15 minutes. The resource will try restarting itself again every 15 minutes instead every hour until it’s brought back up online. ","date":"Monday, Jan 1, 2018","objectID":"/how-to-adjust-windows-failover-cluster-response-to-resource-failure-policy/:0:0","tags":["iaas","wfc","windows","failover","cluster","failovercluster"],"title":"How to adjust Windows Failover Cluster 'Response to Resource Failure' Policy","uri":"/how-to-adjust-windows-failover-cluster-response-to-resource-failure-policy/"},{"categories":["Azure","Troubleshooting"],"content":"In case you get this error below, this error is mostly due to outdated Modules or at least in this case the AzureRM module. Your Azure credentials have not been set up or have expired, please run Login-AzureRMAccount to set up your Azure credentials. Easily go ahead and update your PowerShell or Azure PowerShell Modules to the latest version 4.4.0 and it should be gone. You can do this while easily using Update-Module or just go ahead and use Install-Module AzureRm -Force ","date":"Thursday, Oct 26, 2017","objectID":"/expired-azure-credentials/:0:0","tags":["automation","credentials","az"],"title":"Expired Azure Credentials","uri":"/expired-azure-credentials/"},{"categories":["WordPress"],"content":"I’m not quite sure why WordPress does this but it seems to happen after some major upgrades or if one of your themes is not aligned correctly. The editor is jumping up and down while writing posts and this drives me insane! It seems not to happen everytime but mostly after a wordpress update happened or changing something on the interface. Nevertheless if oyu want ot have it disbaled easily go to Screen Options at the upper right corner of your screen and toggle it. Under Addition Settings you can see a field called Enable full-height editor and distraction-free functionality. Untick it and be happy! ","date":"Friday, May 19, 2017","objectID":"/wordpress-editor-jump-fix/:0:0","tags":["wordpress","fix"],"title":"Wordpress Editor Jump Fix","uri":"/wordpress-editor-jump-fix/"}]