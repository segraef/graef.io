<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><meta http-equiv=X-UA-Compatible content="IE=edge, chrome=1"><title>Build your own GPT-Powered AI Voice Assistant with Azure OpenAI and Cognitive Services - Automate everything </title><meta name=Description content="Automate everything - Sebastian Gräf"><meta property="og:url" content="https://graef.io/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/"><meta property="og:site_name" content="Automate everything "><meta property="og:title" content="Build your own GPT-Powered AI Voice Assistant with Azure OpenAI and Cognitive Services"><meta property="og:description" content="Let’s build your own AI voice assistant which is better than Amazon’s Alexa using Azure Cognitive Services (SST and TTS) and OpenAI. All you need is a bit of basic Python understanding, an Azure account, a microphone and a speaker. This will take about 15 minutes to set up and you’ll be done."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-06-11T16:37:59+10:00"><meta property="article:modified_time" content="2023-06-11T16:37:59+10:00"><meta property="article:tag" content="Gpt"><meta property="article:tag" content="AI"><meta property="article:tag" content="Azure"><meta property="article:tag" content="Cognitive"><meta property="article:tag" content="Openai"><meta property="article:tag" content="Nlp"><meta property="og:image" content="https://graef.io/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/example.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://graef.io/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/example.png"><meta name=twitter:title content="Build your own GPT-Powered AI Voice Assistant with Azure OpenAI and Cognitive Services"><meta name=twitter:description content="Let’s build your own AI voice assistant which is better than Amazon’s Alexa using Azure Cognitive Services (SST and TTS) and OpenAI. All you need is a bit of basic Python understanding, an Azure account, a microphone and a speaker. This will take about 15 minutes to set up and you’ll be done."><meta name=twitter:site content="@segraef"><meta name=application-name content="graef.io - Sebastian Gräf"><meta name=apple-mobile-web-app-title content="graef.io - Sebastian Gräf"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://graef.io/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/><link rel=prev href=https://graef.io/from-code-to-canvas-a-guide-for-prompting-stunning-ai-art-with-midjourney-1/><link rel=next href=https://graef.io/create-your-own-official-azure-pipeline-agents-images-and-github-actions-runner-images/><link rel=stylesheet href=/lib/normalize/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=/lib/fontawesome-free/all.min.css><link rel=stylesheet href=/lib/animate/animate.min.css><meta name=google-site-verification content="google-site-verification=081I19l1P1J3FFLaw1uKtAtY5KcJx_Z9ywiKt60VGP4"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Build your own GPT-Powered AI Voice Assistant with Azure OpenAI and Cognitive Services","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/graef.io\/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai\/"},"image":["https:\/\/graef.io\/logo.png"],"genre":"posts","keywords":"gpt, ai, azure, cognitive, openai, nlp, synthesis, language, processing, mycroft, picroft","wordcount":709,"url":"https:\/\/graef.io\/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai\/","datePublished":"2023-06-11T16:37:59+10:00","dateModified":"2023-06-11T16:37:59+10:00","publisher":{"@type":"Organization","name":"greaf.io","logo":"https:\/\/graef.io\/logo.png"},"author":{"@type":"Person","name":"Author"},"description":""}</script><script type=text/javascript>window.location.hostname!=="localhost"&&function(e,t,n,s,o,i,a){e[n]=e[n]||function(){(e[n].q=e[n].q||[]).push(arguments)},i=t.createElement(s),i.async=1,i.src="https://www.clarity.ms/tag/"+o,a=t.getElementsByTagName(s)[0],a.parentNode.insertBefore(i,a)}(window,document,"clarity","script","p0l7yeco82")</script></head><body header-desktop=auto header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":"light"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"light"==="dark")&&document.body.setAttribute("theme","dark")</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="Automate everything "><img class="lazyload logo" src=/svg/loading.min.svg data-src=/logo.png data-srcset="/logo.png, /logo.png 1.5x, /logo.png 2x" data-sizes=auto alt=/logo.png title=/logo.png></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/ title=Posts>Posts </a><a class=menu-item href=/categories/projects/ title=Projects>Projects </a><a class=menu-item href=/categories/til/ title="Today I learned">TIL </a><a class=menu-item href=/tags/ title=Tags>Tags </a><a class=menu-item href=/categories/ title=Categories>Categories </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder="Search titles or contents..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fas fa-search fa-fw"></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fas fa-times-circle fa-fw"></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin"></i>
</span></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw"></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="Automate everything "><img class="lazyload logo" src=/svg/loading.min.svg data-src=/logo.png data-srcset="/logo.png, /logo.png 1.5x, /logo.png 2x" data-sizes=auto alt=/logo.png title=/logo.png></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="Search titles or contents..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fas fa-search fa-fw"></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fas fa-times-circle fa-fw"></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin"></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><a class=menu-item href=/posts/ title=Posts>Posts</a><a class=menu-item href=/categories/projects/ title=Projects>Projects</a><a class=menu-item href=/categories/til/ title="Today I learned">TIL</a><a class=menu-item href=/tags/ title=Tags>Tags</a><a class=menu-item href=/categories/ title=Categories>Categories</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animated flipInX">Build your own GPT-Powered AI Voice Assistant with Azure OpenAI and Cognitive Services</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw"></i>Author</a></span>&nbsp;<span class=post-category>included in <a href=/categories/ai/><i class="far fa-folder fa-fw"></i>AI</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="Sunday, Jun 11, 2023">Sunday, Jun 11, 2023</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;709 words&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;4 minutes&nbsp;</div></div><div class="details toc" id=toc-static kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#prerequisites>Prerequisites</a></li><li><a href=#workflow>Workflow</a></li><li><a href=#setting-up-azure-cognitive-services>Setting up Azure Cognitive Services</a></li><li><a href=#integrating-azure-openai>Integrating Azure OpenAI</a></li><li><a href=#recognizing-and-generating-speech>Recognizing and Generating Speech</a></li><li><a href=#synthesizing-speech-output>Synthesizing Speech Output</a></li><li><a href=#example-and-code>Example and Code</a></li><li><a href=#next-steps>Next steps</a></li></ul></nav></div></div><div class=content id=content><p>Let&rsquo;s build your own AI voice assistant which is better than Amazon&rsquo;s <strong>Alexa</strong> using Azure Cognitive Services (SST and TTS) and OpenAI. All you need is a bit of basic Python understanding, an Azure account, a microphone and a speaker. This will take about 15 minutes to set up and you&rsquo;ll be done.</p><blockquote><p>For those who don&rsquo;t have patience and want to get it done immediately: A working version, written in under 80 lines of code can be found <a href=https://github.com/segraef/PAi/blob/main/start.py target=_blank rel="noopener noreffer">here</a>.</p></blockquote><p>By combining the speech recognition and synthesis capabilities of Azure with the power of OpenAI&rsquo;s GPT model, we can create an intelligent and conversational voice assistant. Let me provide you step-by-step instructions and code examples to help you get started.</p><h2 id=prerequisites>Prerequisites</h2><p>Before getting started make sure you have the following prerequisites installed on your system:</p><ul><li><a href=https://portal.azure.com/#create/Microsoft.CognitiveServicesSpeechServices target=_blank rel="noopener noreffer">Create a Speech resource </a>in Azure</li><li>An Azure OpenAI Service resource with a model deployed. For more information about model deployment, see the <a href=https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource target=_blank rel="noopener noreffer">resource deployment guide</a>.</li><li>Python (at least 3.7.1)</li><li>Azure Cognitive Services Speech SDK</li><li>Python libraries: openai, os, requests, json</li></ul><blockquote><p>Currently, access to <strong>Azure OpenAI</strong> is granted only by application. You can apply for access to Azure OpenAI by completing the form at <a href=https://aka.ms/oai/access target=_blank rel="noopener noreffer">https://aka.ms/oai/access</a>.</p></blockquote><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># Azure Cognitive Services Speech SDK</span>
</span></span><span class=line><span class=cl>pip install azure-cognitiveservices-speech
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># OpenAI Python Library</span>
</span></span><span class=line><span class=cl>pip install openai
</span></span></code></pre></td></tr></table></div></div><h2 id=workflow>Workflow</h2><p>Let me give you the bigger picture upfront for a better understanding what we&rsquo;re going to do:</p><div class=mermaid id=id-1></div><ol><li>The Speech-to-Text (STT) <code>SpeechRecognizer</code> component from Cognitive Services recognizes your speech and language and converts it into text.</li><li>The OpenAI component sits in between which acts as the AI voice assistant component, it takes the input from the <code>SpeechRecognizer</code> and generates an intelligent response using a GPT-model.</li><li>The repsonse will be synthesized accordingly into Text-To-Speech (TTS) by the <code>SpeechSynthesizer</code>.</li></ol><h2 id=setting-up-azure-cognitive-services>Setting up Azure Cognitive Services</h2><p>First, obtain your Azure Cognitive Services subscription key and region.</p><p><img class=lazyload src=/svg/loading.min.svg data-src=speech.png data-srcset="/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/speech.png, speech.png 1.5x, /building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/speech.png 2x" data-sizes=auto alt=/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/speech.png title="Alt text"></p><p>Then, using the Azure Cognitive Services Speech SDK, you can configure the <code>SpeechConfig</code> object with your subscription key and region. For example:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># Save as environment variable</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>cognitive_services_speech_key</span><span class=o>=</span>&lt;YOUR_API_KEY&gt;
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>azure.cognitiveservices.speech</span> <span class=k>as</span> <span class=nn>speechsdk</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>speech_key</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;cognitive_services_speech_key&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>service_region</span> <span class=o>=</span> <span class=s2>&#34;australiaeast&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>speech_config</span> <span class=o>=</span> <span class=n>speechsdk</span><span class=o>.</span><span class=n>SpeechConfig</span><span class=p>(</span><span class=n>subscription</span><span class=o>=</span><span class=n>speech_key</span><span class=p>,</span> <span class=n>region</span><span class=o>=</span><span class=n>service_region</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>speech_config</span><span class=o>.</span><span class=n>speech_synthesis_voice_name</span> <span class=o>=</span> <span class=s2>&#34;en-US-AshleyNeural&#34;</span>
</span></span></code></pre></td></tr></table></div></div><p>This configuration allows you to access Azure&rsquo;s speech recognition and synthesis capabilities.
All voices can be found <a href="https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/language-support?tabs=tts" target=_blank rel="noopener noreffer">here</a>.</p><h2 id=integrating-azure-openai>Integrating Azure OpenAI</h2><p>In addition to Azure Cognitive Services, we will integrate OpenAI&rsquo;s GPT model to generate intelligent responses. First, ensure you have an OpenAI API key.</p><figure><a class=lightgallery href=/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/openai.png title=/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/openai.png data-thumbnail=/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/openai.png data-sub-html="<h2>Azure OpenAI Keys.</h2>"><img class=lazyload src=/svg/loading.min.svg data-src=openai.png data-srcset="/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/openai.png, openai.png 1.5x, /building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/openai.png 2x" data-sizes=auto alt=/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/openai.png></a><figcaption class=image-caption>Azure OpenAI Keys.</figcaption></figure><p>Then, using the OpenAI Python library, you can configure the API with your key. For example:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># Save as environment variable</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>openai_api_key</span><span class=o>=</span>&lt;YOUR_API_KEY&gt;
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>openai_api_base</span><span class=o>=</span>https://&lt;YOUR_OPENAI_SERVICE&gt;.openai.azure.com
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>openai</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>openai</span><span class=o>.</span><span class=n>api_key</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;openai_api_key&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>openai</span><span class=o>.</span><span class=n>api_base</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;openai_api_base&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>With this integration, we can leverage the power of GPT to generate contextually relevant responses based on user input.</p><h2 id=recognizing-and-generating-speech>Recognizing and Generating Speech</h2><p>The core functionality of our voice assistant involves recognizing user speech and generating appropriate responses. Azure Cognitive Services provides the SpeechRecognizer class for speech recognition. Here&rsquo;s an example of recognizing speech from an audio input stream:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Process the recognized text</span>
</span></span><span class=line><span class=cl><span class=n>speech_recognizer</span> <span class=o>=</span> <span class=n>speechsdk</span><span class=o>.</span><span class=n>SpeechRecognizer</span><span class=p>(</span><span class=n>speech_config</span><span class=o>=</span><span class=n>speech_config</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>speech_recognizer</span><span class=o>.</span><span class=n>recognize_once</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>result</span><span class=o>.</span><span class=n>reason</span> <span class=o>==</span> <span class=n>speechsdk</span><span class=o>.</span><span class=n>ResultReason</span><span class=o>.</span><span class=n>RecognizedSpeech</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>recognized_text</span> <span class=o>=</span> <span class=n>result</span><span class=o>.</span><span class=n>text</span>
</span></span></code></pre></td></tr></table></div></div><p>Once the user&rsquo;s speech is recognized, we can use OpenAI&rsquo;s GPT model to generate a response. Here&rsquo;s an example of generating a response using OpenAI:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Process the generated response</span>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>openai</span><span class=o>.</span><span class=n>Completion</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>engine</span><span class=o>=</span><span class=s2>&#34;davinci&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>prompt</span><span class=o>=</span><span class=n>recognized_text</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>max_tokens</span><span class=o>=</span><span class=mi>100</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>generated_response</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>text</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=synthesizing-speech-output>Synthesizing Speech Output</h2><p>To provide a natural voice output, Azure Cognitive Services offers the <code>SpeechSynthesizer</code> class for speech synthesis. You can synthesize the generated response into speech using the SpeechSynthesizer&rsquo;s <code>speak_text_async</code> method. Here&rsquo;s an example:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Play or save the synthesized speech</span>
</span></span><span class=line><span class=cl><span class=n>speech_synthesizer</span> <span class=o>=</span> <span class=n>speechsdk</span><span class=o>.</span><span class=n>SpeechSynthesizer</span><span class=p>(</span><span class=n>speech_config</span><span class=o>=</span><span class=n>speech_config</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>speech_synthesizer</span><span class=o>.</span><span class=n>speak_text_async</span><span class=p>(</span><span class=n>generated_response</span><span class=p>)</span><span class=o>.</span><span class=n>get</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>result</span><span class=o>.</span><span class=n>reason</span> <span class=o>==</span> <span class=n>speechsdk</span><span class=o>.</span><span class=n>ResultReason</span><span class=o>.</span><span class=n>SynthesizingAudioCompleted</span><span class=p>:</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=example-and-code>Example and Code</h2><p><img class=lazyload src=/svg/loading.min.svg data-src=example.png data-srcset="/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/example.png, example.png 1.5x, /building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/example.png 2x" data-sizes=auto alt=/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/example.png title=/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/example.png></p><p><a href=https://github.com/segraef/PAi target=_blank rel="noopener noreffer">Here</a> is a working version written in Python.</p><h2 id=next-steps>Next steps</h2><p>We covered the process of building a GPT-powered AI voice assistant using Azure Cognitive Services and OpenAI. The next step is to port this onto a Raspberry Pi which we equip with a speaker and microphone. More details in the next post.</p><div class="details admonition info open"><div class="details-summary admonition-title"><i class="icon fas fa-info-circle fa-fw"></i>References<i class="details-icon fas fa-angle-right fa-fw"></i></div><div class=details-content><div class=admonition-content><ul><li><a href=https://portal.azure.com/#create/Microsoft.CognitiveServicesSpeechServices target=_blank rel="noopener noreffer">Create a Speech resource</a></li><li><a href=https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource target=_blank rel="noopener noreffer">OpenAI resource deployment guide</a>.</li><li><a href=https://aka.ms/oai/access target=_blank rel="noopener noreffer">OpenAI Access Request</a></li><li><a href=https://github.com/segraef/PAi target=_blank rel="noopener noreffer">github.com/PAi</a></li></ul></div></div></div></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on Sunday, Jun 11, 2023</span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=https://graef.io/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/ data-title="Build your own GPT-Powered AI Voice Assistant with Azure OpenAI and Cognitive Services" data-via=segraef data-hashtags=gpt,ai,azure,cognitive,openai,nlp,synthesis,language,processing,mycroft,picroft><i class="fab fa-twitter fa-fw"></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://graef.io/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/ data-hashtag=gpt><i class="fab fa-facebook-square fa-fw"></i></a><a href=javascript:void(0); title="Share on Linkedin" data-sharer=linkedin data-url=https://graef.io/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/><i class="fab fa-linkedin fa-fw"></i></a><a href=javascript:void(0); title="Share on WhatsApp" data-sharer=whatsapp data-url=https://graef.io/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/ data-title="Build your own GPT-Powered AI Voice Assistant with Azure OpenAI and Cognitive Services" data-web><i class="fab fa-whatsapp fa-fw"></i></a><a href=javascript:void(0); title="Share on Reddit" data-sharer=reddit data-url=https://graef.io/building-your-own-gpt-powered-ai-voice-assistant-with-azure-cognitive-services-and-openai/><i class="fab fa-reddit fa-fw"></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/gpt/>Gpt</a>,&nbsp;<a href=/tags/ai/>AI</a>,&nbsp;<a href=/tags/azure/>Azure</a>,&nbsp;<a href=/tags/cognitive/>Cognitive</a>,&nbsp;<a href=/tags/openai/>Openai</a>,&nbsp;<a href=/tags/nlp/>Nlp</a>,&nbsp;<a href=/tags/synthesis/>Synthesis</a>,&nbsp;<a href=/tags/language/>Language</a>,&nbsp;<a href=/tags/processing/>Processing</a>,&nbsp;<a href=/tags/mycroft/>Mycroft</a>,&nbsp;<a href=/tags/picroft/>Picroft</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/from-code-to-canvas-a-guide-for-prompting-stunning-ai-art-with-midjourney-1/ class=prev rel=prev title="From Code to Canvas: A Guide for Prompting Stunning AI Art with MidJourney (1/3)"><i class="fas fa-angle-left fa-fw"></i>From Code to Canvas: A Guide for Prompting Stunning AI Art with MidJourney (1/3)</a>
<a href=/create-your-own-official-azure-pipeline-agents-images-and-github-actions-runner-images/ class=next rel=next title="Create your own official Azure Pipelines Agent Images and GitHub Actions Runner Images">Create your own official Azure Pipelines Agent Images and GitHub Actions Runner Images<i class="fas fa-angle-right fa-fw"></i></a></div></div><div id=comments><div id=utterances></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://utteranc.es/>Utterances</a>.</noscript></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2021 - 2025</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank></a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw"></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw"></i></a></div><link rel=stylesheet href=/lib/lightgallery/lightgallery.min.css><link rel=stylesheet href=/lib/katex/katex.min.css><link rel=stylesheet href=/lib/katex/copy-tex.min.css><script type=text/javascript src=/lib/smooth-scroll/smooth-scroll.min.js></script><script type=text/javascript src=/lib/autocomplete/autocomplete.min.js></script><script type=text/javascript src=/lib/lunr/lunr.min.js></script><script type=text/javascript src=/lib/lazysizes/lazysizes.min.js></script><script type=text/javascript src=/lib/lightgallery/lightgallery.min.js></script><script type=text/javascript src=/lib/lightgallery/lg-thumbnail.min.js></script><script type=text/javascript src=/lib/lightgallery/lg-zoom.min.js></script><script type=text/javascript src=/lib/clipboard/clipboard.min.js></script><script type=text/javascript src=/lib/sharer/sharer.min.js></script><script type=text/javascript src=/lib/katex/katex.min.js></script><script type=text/javascript src=/lib/katex/auto-render.min.js></script><script type=text/javascript src=/lib/katex/copy-tex.min.js></script><script type=text/javascript src=/lib/katex/mhchem.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:20},comment:{utterances:{darkTheme:"github-dark",issueTerm:"pathname",label:"",lightTheme:"github-light",repo:"segraef/graef.io"}},lightGallery:{actualSize:!1,exThumbImage:"data-thumbnail",hideBarsDelay:2e3,selector:".lightgallery",speed:400,thumbContHeight:80,thumbWidth:80,thumbnail:!0},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{highlightTag:"em",lunrIndexURL:"/index.json",maxResultLength:10,noResultsFound:"No results found",snippetLength:30,type:"lunr"}}</script><script type=text/javascript src=/js/theme.min.js></script><script type=text/javascript>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","UA-99599711-2",{anonymize_ip:!0})</script><script type=text/javascript src="https://www.googletagmanager.com/gtag/js?id=UA-99599711-2" async></script></body></html>